{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4675 entries, 8137 to 20797\n",
      "Data columns (total 7 columns):\n",
      "id                       4675 non-null int64\n",
      "source                   4675 non-null object\n",
      "title                    4675 non-null object\n",
      "pilot1_high_agreement    4675 non-null int64\n",
      "similar_persps           4675 non-null object\n",
      "more_than_two_tokens     4675 non-null int64\n",
      "pilot1_have_stance       4675 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 292.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# First, use heuristics to get google perspectives that are not valid but are complete sentences.\n",
    "import pandas as pd\n",
    "\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# Only keep the google ones that (1) high agreement (2) Non-valid perspective\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 0) & (pdf.source == 'google')]\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2427 entries, 8148 to 20792\n",
      "Data columns (total 8 columns):\n",
      "id                       2427 non-null int64\n",
      "source                   2427 non-null object\n",
      "title                    2427 non-null object\n",
      "pilot1_high_agreement    2427 non-null int64\n",
      "similar_persps           2427 non-null object\n",
      "more_than_two_tokens     2427 non-null int64\n",
      "pilot1_have_stance       2427 non-null int64\n",
      "legit_sentence           2427 non-null bool\n",
      "dtypes: bool(1), int64(4), object(3)\n",
      "memory usage: 154.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Produce ids of the google perspectives that (1) high agreement (2) Non-valid perspective\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "\n",
    "def complete_sentence_candidate(text, token_length=5):\n",
    "    text = text.rstrip()\n",
    "    toks = word_tokenize(text)\n",
    "    legit = text[0].isupper() and toks[-1] == '.' and len(toks) > token_length\n",
    "    return legit\n",
    "\n",
    "pdf['legit_sentence'] = False\n",
    "for idx, row in pdf.iterrows():\n",
    "    if complete_sentence_candidate(row.title):\n",
    "        pdf.at[idx, \"legit_sentence\"] = True\n",
    "\n",
    "legit_sent_pdf = pdf[pdf.legit_sentence == True]\n",
    "legit_sent_pdf.info()\n",
    "\n",
    "index = legit_sent_pdf.id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/non_valid_high_agreement_google_persps.json\"\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3985 entries, 0 to 8133\n",
      "Data columns (total 7 columns):\n",
      "id                       3985 non-null int64\n",
      "source                   3985 non-null object\n",
      "title                    3985 non-null object\n",
      "pilot1_high_agreement    3985 non-null int64\n",
      "similar_persps           3985 non-null object\n",
      "more_than_two_tokens     3985 non-null int64\n",
      "pilot1_have_stance       3985 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 249.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3985 entries, 19372 to 23602\n",
      "Data columns (total 12 columns):\n",
      "id                        3985 non-null int64\n",
      "claim_id                  3985 non-null int64\n",
      "perspective_id            3985 non-null int64\n",
      "vote_support              3985 non-null int64\n",
      "vote_leaning_support      3985 non-null int64\n",
      "vote_leaning_undermine    3985 non-null int64\n",
      "vote_undermine            3985 non-null int64\n",
      "vote_not_valid            3985 non-null int64\n",
      "p_i_5                     3985 non-null float64\n",
      "p_i_3                     3985 non-null float64\n",
      "label_3                   3985 non-null object\n",
      "label_5                   3985 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 404.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 534 entries, 19511 to 23420\n",
      "Data columns (total 12 columns):\n",
      "id                        534 non-null int64\n",
      "claim_id                  534 non-null int64\n",
      "perspective_id            534 non-null int64\n",
      "vote_support              534 non-null int64\n",
      "vote_leaning_support      534 non-null int64\n",
      "vote_leaning_undermine    534 non-null int64\n",
      "vote_undermine            534 non-null int64\n",
      "vote_not_valid            534 non-null int64\n",
      "p_i_5                     534 non-null float64\n",
      "p_i_3                     534 non-null float64\n",
      "label_3                   534 non-null object\n",
      "label_5                   534 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 54.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. Produce ids of perspectives that (1) support or undermine (2) high agreement (aka > 0.5) (3) Original\n",
    "# (4) have >= 15 other perspectives connected to the same claim \n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# (1) support or undermine (2) high agreement (aka > 0.5) (3) Original\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 1) & (pdf.source != \"google\")]\n",
    "pdf.info()\n",
    "\n",
    "# Same criteria but in different table, for sanity check\n",
    "re_step1_path = \"../data/database_output/re-step1/webapp_restep1results.csv\"\n",
    "step1_df = pd.read_csv(re_step1_path)\n",
    "\n",
    "step1_df = step1_df[(step1_df.p_i_3 > 0.5) & (step1_df.label_3.isin([\"S\", \"U\"])) & (step1_df.perspective_id < 8136)]\n",
    "step1_df.info()\n",
    "\n",
    "# Counts of how many perspectives each claim have\n",
    "# For claims with > 10, get all perspectives ids\n",
    "claim_persp_count_df = step1_df[['claim_id', 'perspective_id']].groupby(['claim_id']).count()\n",
    "claim_persp_count_df = claim_persp_count_df[claim_persp_count_df.perspective_id > 10]\n",
    "claim_ids = claim_persp_count_df.index.tolist()\n",
    "\n",
    "many_p_df = step1_df.loc[step1_df[\"claim_id\"].isin(claim_ids)]\n",
    "many_p_df.info()\n",
    "index = many_p_df.perspective_id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/perspective/claim_with_more_than_10_persp_perspectives.json\"\n",
    "\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1652 entries, 8140 to 20738\n",
      "Data columns (total 7 columns):\n",
      "id                       1652 non-null int64\n",
      "source                   1652 non-null object\n",
      "title                    1652 non-null object\n",
      "pilot1_high_agreement    1652 non-null int64\n",
      "similar_persps           1652 non-null object\n",
      "more_than_two_tokens     1652 non-null int64\n",
      "pilot1_have_stance       1652 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 103.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 954 entries, 8140 to 20738\n",
      "Data columns (total 8 columns):\n",
      "id                       954 non-null int64\n",
      "source                   954 non-null object\n",
      "title                    954 non-null object\n",
      "pilot1_high_agreement    954 non-null int64\n",
      "similar_persps           954 non-null object\n",
      "more_than_two_tokens     954 non-null int64\n",
      "pilot1_have_stance       954 non-null int64\n",
      "legit_sentence           954 non-null bool\n",
      "dtypes: bool(1), int64(4), object(3)\n",
      "memory usage: 60.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 3, produce high agreement + support/undermine + complete sentence google perspectives\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# Only keep the google ones that (1) high agreement (2) Non-valid perspective\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 1) & (pdf.source == 'google')]\n",
    "pdf.info()\n",
    "\n",
    "pdf['legit_sentence'] = False\n",
    "for idx, row in pdf.iterrows():\n",
    "    if complete_sentence_candidate(row.title):\n",
    "        pdf.at[idx, \"legit_sentence\"] = True\n",
    "\n",
    "legit_sent_pdf = pdf[pdf.legit_sentence == True]\n",
    "legit_sent_pdf.info()\n",
    "\n",
    "index = legit_sent_pdf.id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/valid_high_agreement_google_persps.json\"\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1488 entries, 4161 to 20738\n",
      "Data columns (total 7 columns):\n",
      "id                       1488 non-null int64\n",
      "source                   1488 non-null object\n",
      "title                    1488 non-null object\n",
      "pilot1_high_agreement    1488 non-null int64\n",
      "similar_persps           1488 non-null object\n",
      "more_than_two_tokens     1488 non-null int64\n",
      "pilot1_have_stance       1488 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 93.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Now index results from step 2 and step 3 in lucene\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "google_valid_stance = \"../data/pilot17_making_the_dataset/indices/valid_high_agreement_google_persps.json\"\n",
    "potential_equivalent_original = \"../data/pilot17_making_the_dataset/indices/perspective/claim_with_more_than_10_persp_perspectives.json\"\n",
    "\n",
    "with open(google_valid_stance) as fin:\n",
    "    gvs_pids = json.load(fin)\n",
    "\n",
    "with open(potential_equivalent_original) as fin:\n",
    "    peo_pids = json.load(fin)\n",
    "    \n",
    "to_be_indexed_pids = set(gvs_pids + peo_pids)\n",
    "\n",
    "pdf = pdf[pdf.id.isin(to_be_indexed_pids)]\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now index results from step 2 and step 3 in lucene\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(['http://bronte.cs.illinois.edu'],port=8080, timeout=30)\n",
    "\n",
    "# Create indices \n",
    "index_name = \"potentially_equivalent_perspectives\"\n",
    "\n",
    "# es.indices.delete(index_name)\n",
    "es.indices.create(index_name)\n",
    "\n",
    "for idx, row in pdf.iterrows():\n",
    "    if row.title:\n",
    "        doc = {\n",
    "            \"id\" : row.id,\n",
    "            \"title\" : row.title\n",
    "        }\n",
    "        es.index(index=index_name, doc_type='text', id=row.id, body=doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those in the original \"potentially equivalent\" perspectives, retrieve the results from index created in previous cell\n",
    "def get_top_potential_equivalent_perspectives(text, num_cands=50):\n",
    "    res = es.search(index=\"potentially_equivalent_perspectives\", doc_type=\"text\", body={\"query\": {\"match\": {\"title\": text}}}, size=num_cands)\n",
    "    # print(\"%d documents found:\" % res['hits']['total'])\n",
    "    output = []\n",
    "    for doc in res['hits']['hits']:\n",
    "        pid = doc['_source'][\"id\"]\n",
    "        score = doc['_score']\n",
    "        perspective_text = doc['_source'][\"title\"]\n",
    "        output.append((perspective_text, pid, score))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "origin_pdf = pdf[pdf.id.isin(peo_pids)]\n",
    "origin_pdf.info()\n",
    "\n",
    "# Use this to find all claims connected to this perspective\n",
    "re_step1_path = \"../data/database_output/re-step1/webapp_restep1results.csv\"\n",
    "step1_df = pd.read_csv(re_step1_path)\n",
    "step1_df = step1_df[(step1_df.p_i_3 > 0.5) & (step1_df.label_3.isin([\"S\", \"U\"]))]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Query candidates for each perspectives, only retain the ones that share the same claim.\n",
    "for idx, row in origin_pdf.iterrows():\n",
    "    pid = row.id\n",
    "    cands = get_top_potential_equivalent_perspectives(row.title)\n",
    "    \n",
    "    associated_claims = step1_df[step1_df.perspective_id == pid].claim_id.unique()\n",
    "    peer_perspective_pids = set(step1_df[step1_df.claim_id.isin(associated_claims)].perspective_id.unique())\n",
    "    \n",
    "    cands = [c[1] for c in cands]\n",
    "    cands = [c for c in cands if c in peer_perspective_pids]\n",
    "    data.append({\n",
    "        \"perspective_id\": pid,\n",
    "        \"candidates\": cands\n",
    "    })\n",
    "\n",
    "out_path = \"../data/pilot17_making_the_dataset/persps_of_claims_with_gt10_persps.json\"\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence count = 8092\n",
      "Persectives count = 11164\n",
      "Claim count = 908\n"
     ]
    }
   ],
   "source": [
    "# Now actually making the dataset!!\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "#################################\n",
    "#   List of all files we need   #\n",
    "#################################\n",
    "\n",
    "# Tables, exported fresh from the database!\n",
    "claim_table = \"../data/pilot17_making_the_dataset/webapp_claim.csv\"\n",
    "perspective_table = \"../data/pilot17_making_the_dataset/webapp_perspective.csv\"\n",
    "evidence_table = \"../data/pilot17_making_the_dataset/webapp_evidence.csv\"\n",
    "\n",
    "re_step1_table = \"../data/pilot17_making_the_dataset/webapp_restep1results.csv\"\n",
    "\n",
    "# Evidence verification result from step 14\n",
    "evidence_verification_result = \"../data/pilot14_step3_pilot/annotation_counts_label.csv\"\n",
    "\n",
    "# Paraphrase generation + filtering result from step 16\n",
    "step16_result = \"../data/pilot16_paraphrase/verification_counts_label.csv\"\n",
    "\n",
    "\n",
    "#################################\n",
    "#         Output path           #\n",
    "#################################\n",
    "out_dir = \"../data/dataset/\"\n",
    "\n",
    "def make_dataset(out_directory, version=\"0.1\"):\n",
    "    \"\"\"\n",
    "    Make the dataset in a few steps \n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: make evidences\n",
    "    # (Exclude empty ones)\n",
    "    evi_out_path = os.path.join(out_directory, \"evidence_pool_v\" + version + \".json\")\n",
    "    evi_data = []\n",
    "    \n",
    "    edf = pd.read_csv(evidence_table).dropna()\n",
    "    \n",
    "    for idx, row in edf.iterrows():\n",
    "        evi_data.append({\n",
    "            \"eId\" : row.id,\n",
    "            \"text\" : row.content,\n",
    "            \"source\" : row.source\n",
    "        })\n",
    "    \n",
    "    with open(evi_out_path, 'w') as fout:\n",
    "        print(\"Evidence count = {}\".format(len(edf.index)))\n",
    "        json.dump(evi_data, fout)\n",
    "    \n",
    "    \n",
    "    # Step 2: Make perspectives\n",
    "    # Component 1: Original perspectives with high agreement and stance\n",
    "    # Component 2: Google perspectives with high agreement and no stance\n",
    "    # Component 3: Paraphrase perspectives \n",
    "    persp_out_path = os.path.join(out_directory, \"perspective_pool_v\" + version + \".json\")\n",
    "    persp_data = {} \n",
    "    \n",
    "    pdf = pd.read_csv(perspective_table).dropna()\n",
    "    \n",
    "    comp1_pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.source.isin([\"idebate\", \"debatewise\", \"procon\"]))]\n",
    "    \n",
    "    # See above on how we generated the index of component 2\n",
    "    comp2_index_path = \"../data/pilot17_making_the_dataset/indices/perspective/non_valid_high_agreement_google_persps.json\"\n",
    "    comp2_pid_list = json.load(open(comp2_index_path))\n",
    "    comp2_pdf = pdf[pdf.id.isin(comp2_pid_list)]\n",
    "    \n",
    "    # Component 3: we use experiment results from pilot 16 \n",
    "    pilot16_df = pd.read_csv(step16_result)\n",
    "    pilot16_df = pilot16_df[pilot16_df.majority_vote_yes == 'YES']\n",
    "    comp3_pids = pilot16_df.paraphrase_perspective.unique()\n",
    "    comp3_pdf = pdf[pdf.id.isin(comp3_pids)]\n",
    "    \n",
    "    for _df in [comp1_pdf, comp2_pdf, comp3_pdf]:\n",
    "        for idx, row in _df.iterrows():\n",
    "            pid = row.id\n",
    "        \n",
    "            if pid not in persp_data:\n",
    "                persp_data[pid] = {\n",
    "                    'pId' : pid,\n",
    "                    'text': row.title,\n",
    "                    \"source\" : row.source\n",
    "                }\n",
    "\n",
    "    \n",
    "    with open(persp_out_path, 'w') as fout:\n",
    "        valid_pids = list(persp_data.keys())\n",
    "        valid_pid_path = \"../data/pilot17_making_the_dataset/indices/perspective/all_in_dataset.json\"\n",
    "        json.dump(valid_pids, open(valid_pid_path, 'w'))\n",
    "        \n",
    "        l = list(persp_data.values())\n",
    "        print(\"Persectives count = {}\".format(len(l)))\n",
    "        json.dump(l, fout)\n",
    "        \n",
    "    \n",
    "    # Step 3: Make Claims with corresponding annotations!!!\n",
    "    # Use results from re-step 1, retain claims that have valid perspectives\n",
    "    claim_out_path = os.path.join(out_directory, \"perspectrum_with_answers_v\" + version + \".json\")\n",
    "    re_step1_df = pd.read_csv(re_step1_table)\n",
    "    cdf = pd.read_csv(claim_table)\n",
    "    \n",
    "    # From step1 results, find original (C, P) pairs with high ag and stance\n",
    "    stance_original_rdf = re_step1_df.loc[(re_step1_df.p_i_3 > 0.5) & (re_step1_df.label_3.isin([\"S\", \"U\"]) & (re_step1_df.perspective_id < 8136))]\n",
    "    \n",
    "    # Load evidence verification result\n",
    "    evi_ver_df = pd.read_csv(evidence_verification_result)\n",
    "    evi_ver_df = evi_ver_df[(evi_ver_df.p_i >= 0.5) & (evi_ver_df.label == 'S')]\n",
    "    \n",
    "    # All pids in our dataset\n",
    "    valid_pids = set(json.load(open(valid_pid_path)))\n",
    "    \n",
    "    # Label code to canonical name mapping\n",
    "    LABEL_MAP = {\n",
    "        \"S\" : \"SUPPORT\",\n",
    "        \"A\" : \"MILDLY_SUPPORT\",\n",
    "        \"B\" : \"MILDLY_UNDERMINE\",\n",
    "        \"U\" : \"UNDERMINE\",\n",
    "        \"N\" : \"NOT_VALID_PERSPECTIVE\",\n",
    "        \"D\" : \"NO_MAJORITY_LABEL\",\n",
    "    }\n",
    "\n",
    "    cids = stance_original_rdf.claim_id.unique()\n",
    "    \n",
    "    c_data = []\n",
    "    \n",
    "    for cid in cids:\n",
    "        claim_row = cdf[cdf.id == cid].iloc[0]\n",
    "        cid = int(claim_row.id)\n",
    "        obj = {\n",
    "            \"cId\" : cid,\n",
    "            \"text\" : claim_row.title,\n",
    "            \"source\" : claim_row.source,\n",
    "            \"perspectives\": []\n",
    "        }\n",
    "        \n",
    "        # Find perspectives! Starting from componant 1\n",
    "        crdf = stance_original_rdf[stance_original_rdf.claim_id == cid]\n",
    "        for idx, row in crdf.iterrows():\n",
    "            \n",
    "            anchor_pid = row.perspective_id\n",
    "            label_3 = LABEL_MAP[row.label_3]\n",
    "            label_5 = LABEL_MAP[row.label_5]\n",
    "            voter_counts = [int(row.vote_support), \n",
    "                            int(row.vote_leaning_support),\n",
    "                            int(row.vote_leaning_undermine), \n",
    "                            int(row.vote_undermine),\n",
    "                            int(row.vote_not_valid)]\n",
    "            \n",
    "            # From the anchor perspective, find all paraphrases\n",
    "            para_pids = pilot16_df[pilot16_df.perspective == anchor_pid].paraphrase_perspective.unique().tolist()\n",
    "            para_pids = [int(x) for x in para_pids]\n",
    "            \n",
    "            # Find all evidences in support of the anchor_pid\n",
    "            evi_ids = list(evi_ver_df[evi_ver_df.perspective == anchor_pid].evidence.unique())\n",
    "            evi_ids = [int(x) for x in evi_ids]\n",
    "            cluster = {\n",
    "                \"pids\": [anchor_pid] + para_pids,\n",
    "                \"stance_label_3\": label_3,\n",
    "                \"stance_label_5\": label_5,\n",
    "                \"voter_counts\": voter_counts,\n",
    "                \"evidence\" : evi_ids\n",
    "            }\n",
    "            obj[\"perspectives\"].append(cluster)\n",
    "            \n",
    "        c_data.append(obj)\n",
    "    \n",
    "    with open(claim_out_path, 'w') as fout:\n",
    "        print(\"Claim count = {}\".format(len(c_data)))\n",
    "        json.dump(c_data, fout)\n",
    "    \n",
    "make_dataset(out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence average token length: 168.46230845279288\n"
     ]
    }
   ],
   "source": [
    "### Compute Average length of tokens in evidences\n",
    "from nltk import word_tokenize\n",
    "\n",
    "evidence_path = \"../data/dataset/evidence_pool_v0.1.json\"\n",
    "\n",
    "evidences = json.load(open(evidence_path))\n",
    "\n",
    "tot_toks_len = 0\n",
    "for evi in evidences:\n",
    "    tot_toks_len += len(word_tokenize(evi[\"text\"]))\n",
    "    \n",
    "print(\"Evidence average token length: {}\".format(tot_toks_len/len(evidences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perspective average token length: 11.947957721246866\n"
     ]
    }
   ],
   "source": [
    "### Compute Average length of tokens in perspectives\n",
    "from nltk import word_tokenize\n",
    "\n",
    "perspective_path = \"../data/dataset/perspective_pool_v0.1.json\"\n",
    "\n",
    "perspective = json.load(open(perspective_path))\n",
    "\n",
    "tot_toks_len = 0\n",
    "for p in perspective:\n",
    "    tot_toks_len += len(word_tokenize(p[\"text\"]))\n",
    "    \n",
    "print(\"Perspective average token length: {}\".format(tot_toks_len/len(perspective)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
