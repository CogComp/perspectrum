{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4675 entries, 8137 to 20797\n",
      "Data columns (total 7 columns):\n",
      "id                       4675 non-null int64\n",
      "source                   4675 non-null object\n",
      "title                    4675 non-null object\n",
      "pilot1_high_agreement    4675 non-null int64\n",
      "similar_persps           4675 non-null object\n",
      "more_than_two_tokens     4675 non-null int64\n",
      "pilot1_have_stance       4675 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 292.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# First, use heuristics to get google perspectives that are not valid but are complete sentences.\n",
    "import pandas as pd\n",
    "\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# Only keep the google ones that (1) high agreement (2) Non-valid perspective\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 0) & (pdf.source == 'google')]\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2427 entries, 8148 to 20792\n",
      "Data columns (total 8 columns):\n",
      "id                       2427 non-null int64\n",
      "source                   2427 non-null object\n",
      "title                    2427 non-null object\n",
      "pilot1_high_agreement    2427 non-null int64\n",
      "similar_persps           2427 non-null object\n",
      "more_than_two_tokens     2427 non-null int64\n",
      "pilot1_have_stance       2427 non-null int64\n",
      "legit_sentence           2427 non-null bool\n",
      "dtypes: bool(1), int64(4), object(3)\n",
      "memory usage: 154.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Produce ids of the google perspectives that (1) high agreement (2) Non-valid perspective\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "\n",
    "def complete_sentence_candidate(text, token_length=5):\n",
    "    text = text.rstrip()\n",
    "    toks = word_tokenize(text)\n",
    "    legit = text[0].isupper() and toks[-1] == '.' and len(toks) > token_length\n",
    "    return legit\n",
    "\n",
    "pdf['legit_sentence'] = False\n",
    "for idx, row in pdf.iterrows():\n",
    "    if complete_sentence_candidate(row.title):\n",
    "        pdf.at[idx, \"legit_sentence\"] = True\n",
    "\n",
    "legit_sent_pdf = pdf[pdf.legit_sentence == True]\n",
    "legit_sent_pdf.info()\n",
    "\n",
    "index = legit_sent_pdf.id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/non_valid_high_agreement_google_persps.json\"\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3985 entries, 0 to 8133\n",
      "Data columns (total 7 columns):\n",
      "id                       3985 non-null int64\n",
      "source                   3985 non-null object\n",
      "title                    3985 non-null object\n",
      "pilot1_high_agreement    3985 non-null int64\n",
      "similar_persps           3985 non-null object\n",
      "more_than_two_tokens     3985 non-null int64\n",
      "pilot1_have_stance       3985 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 249.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3985 entries, 19372 to 23602\n",
      "Data columns (total 12 columns):\n",
      "id                        3985 non-null int64\n",
      "claim_id                  3985 non-null int64\n",
      "perspective_id            3985 non-null int64\n",
      "vote_support              3985 non-null int64\n",
      "vote_leaning_support      3985 non-null int64\n",
      "vote_leaning_undermine    3985 non-null int64\n",
      "vote_undermine            3985 non-null int64\n",
      "vote_not_valid            3985 non-null int64\n",
      "p_i_5                     3985 non-null float64\n",
      "p_i_3                     3985 non-null float64\n",
      "label_3                   3985 non-null object\n",
      "label_5                   3985 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 404.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 534 entries, 19511 to 23420\n",
      "Data columns (total 12 columns):\n",
      "id                        534 non-null int64\n",
      "claim_id                  534 non-null int64\n",
      "perspective_id            534 non-null int64\n",
      "vote_support              534 non-null int64\n",
      "vote_leaning_support      534 non-null int64\n",
      "vote_leaning_undermine    534 non-null int64\n",
      "vote_undermine            534 non-null int64\n",
      "vote_not_valid            534 non-null int64\n",
      "p_i_5                     534 non-null float64\n",
      "p_i_3                     534 non-null float64\n",
      "label_3                   534 non-null object\n",
      "label_5                   534 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 54.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. Produce ids of perspectives that (1) support or undermine (2) high agreement (aka > 0.5) (3) Original\n",
    "# (4) have >= 15 other perspectives connected to the same claim \n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# (1) support or undermine (2) high agreement (aka > 0.5) (3) Original\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 1) & (pdf.source != \"google\")]\n",
    "pdf.info()\n",
    "\n",
    "# Same criteria but in different table, for sanity check\n",
    "re_step1_path = \"../data/database_output/re-step1/webapp_restep1results.csv\"\n",
    "step1_df = pd.read_csv(re_step1_path)\n",
    "\n",
    "step1_df = step1_df[(step1_df.p_i_3 > 0.5) & (step1_df.label_3.isin([\"S\", \"U\"])) & (step1_df.perspective_id < 8136)]\n",
    "step1_df.info()\n",
    "\n",
    "# Counts of how many perspectives each claim have\n",
    "# For claims with > 10, get all perspectives ids\n",
    "claim_persp_count_df = step1_df[['claim_id', 'perspective_id']].groupby(['claim_id']).count()\n",
    "claim_persp_count_df = claim_persp_count_df[claim_persp_count_df.perspective_id > 10]\n",
    "claim_ids = claim_persp_count_df.index.tolist()\n",
    "\n",
    "many_p_df = step1_df.loc[step1_df[\"claim_id\"].isin(claim_ids)]\n",
    "many_p_df.info()\n",
    "index = many_p_df.perspective_id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/perspective/claim_with_more_than_10_persp_perspectives.json\"\n",
    "\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1652 entries, 8140 to 20738\n",
      "Data columns (total 7 columns):\n",
      "id                       1652 non-null int64\n",
      "source                   1652 non-null object\n",
      "title                    1652 non-null object\n",
      "pilot1_high_agreement    1652 non-null int64\n",
      "similar_persps           1652 non-null object\n",
      "more_than_two_tokens     1652 non-null int64\n",
      "pilot1_have_stance       1652 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 103.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 954 entries, 8140 to 20738\n",
      "Data columns (total 8 columns):\n",
      "id                       954 non-null int64\n",
      "source                   954 non-null object\n",
      "title                    954 non-null object\n",
      "pilot1_high_agreement    954 non-null int64\n",
      "similar_persps           954 non-null object\n",
      "more_than_two_tokens     954 non-null int64\n",
      "pilot1_have_stance       954 non-null int64\n",
      "legit_sentence           954 non-null bool\n",
      "dtypes: bool(1), int64(4), object(3)\n",
      "memory usage: 60.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 3, produce high agreement + support/undermine + complete sentence google perspectives\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "# Only keep the google ones that (1) high agreement (2) Non-valid perspective\n",
    "pdf = pdf[(pdf.pilot1_high_agreement == 1) & (pdf.pilot1_have_stance == 1) & (pdf.source == 'google')]\n",
    "pdf.info()\n",
    "\n",
    "pdf['legit_sentence'] = False\n",
    "for idx, row in pdf.iterrows():\n",
    "    if complete_sentence_candidate(row.title):\n",
    "        pdf.at[idx, \"legit_sentence\"] = True\n",
    "\n",
    "legit_sent_pdf = pdf[pdf.legit_sentence == True]\n",
    "legit_sent_pdf.info()\n",
    "\n",
    "index = legit_sent_pdf.id.unique().tolist()\n",
    "indices_out_path = \"../data/pilot17_making_the_dataset/indices/valid_high_agreement_google_persps.json\"\n",
    "with open(indices_out_path, 'w') as fout:\n",
    "    json.dump(index, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1488 entries, 4161 to 20738\n",
      "Data columns (total 7 columns):\n",
      "id                       1488 non-null int64\n",
      "source                   1488 non-null object\n",
      "title                    1488 non-null object\n",
      "pilot1_high_agreement    1488 non-null int64\n",
      "similar_persps           1488 non-null object\n",
      "more_than_two_tokens     1488 non-null int64\n",
      "pilot1_have_stance       1488 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 93.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Now index results from step 2 and step 3 in lucene\n",
    "perspective_db_path = \"../data/database_output/re-step1/webapp_perspective.csv\"\n",
    "pdf = pd.read_csv(perspective_db_path).dropna()\n",
    "\n",
    "google_valid_stance = \"../data/pilot17_making_the_dataset/indices/valid_high_agreement_google_persps.json\"\n",
    "potential_equivalent_original = \"../data/pilot17_making_the_dataset/indices/perspective/claim_with_more_than_10_persp_perspectives.json\"\n",
    "\n",
    "with open(google_valid_stance) as fin:\n",
    "    gvs_pids = json.load(fin)\n",
    "\n",
    "with open(potential_equivalent_original) as fin:\n",
    "    peo_pids = json.load(fin)\n",
    "    \n",
    "to_be_indexed_pids = set(gvs_pids + peo_pids)\n",
    "\n",
    "pdf = pdf[pdf.id.isin(to_be_indexed_pids)]\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now index results from step 2 and step 3 in lucene\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(['http://bronte.cs.illinois.edu'],port=8080, timeout=30)\n",
    "\n",
    "# Create indices \n",
    "index_name = \"potentially_equivalent_perspectives\"\n",
    "\n",
    "# es.indices.delete(index_name)\n",
    "es.indices.create(index_name)\n",
    "\n",
    "for idx, row in pdf.iterrows():\n",
    "    if row.title:\n",
    "        doc = {\n",
    "            \"id\" : row.id,\n",
    "            \"title\" : row.title\n",
    "        }\n",
    "        es.index(index=index_name, doc_type='text', id=row.id, body=doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those in the original \"potentially equivalent\" perspectives, retrieve the results from index created in previous cell\n",
    "def get_top_potential_equivalent_perspectives(text, num_cands=50):\n",
    "    res = es.search(index=\"potentially_equivalent_perspectives\", doc_type=\"text\", body={\"query\": {\"match\": {\"title\": text}}}, size=num_cands)\n",
    "    # print(\"%d documents found:\" % res['hits']['total'])\n",
    "    output = []\n",
    "    for doc in res['hits']['hits']:\n",
    "        pid = doc['_source'][\"id\"]\n",
    "        score = doc['_score']\n",
    "        perspective_text = doc['_source'][\"title\"]\n",
    "        output.append((perspective_text, pid, score))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "origin_pdf = pdf[pdf.id.isin(peo_pids)]\n",
    "origin_pdf.info()\n",
    "\n",
    "# Use this to find all claims connected to this perspective\n",
    "re_step1_path = \"../data/database_output/re-step1/webapp_restep1results.csv\"\n",
    "step1_df = pd.read_csv(re_step1_path)\n",
    "step1_df = step1_df[(step1_df.p_i_3 > 0.5) & (step1_df.label_3.isin([\"S\", \"U\"]))]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Query candidates for each perspectives, only retain the ones that share the same claim.\n",
    "for idx, row in origin_pdf.iterrows():\n",
    "    pid = row.id\n",
    "    cands = get_top_potential_equivalent_perspectives(row.title)\n",
    "    \n",
    "    associated_claims = step1_df[step1_df.perspective_id == pid].claim_id.unique()\n",
    "    peer_perspective_pids = set(step1_df[step1_df.claim_id.isin(associated_claims)].perspective_id.unique())\n",
    "    \n",
    "    cands = [c[1] for c in cands]\n",
    "    cands = [c for c in cands if c in peer_perspective_pids]\n",
    "    data.append({\n",
    "        \"perspective_id\": pid,\n",
    "        \"candidates\": cands\n",
    "    })\n",
    "    \n",
    "out_path = \"../data/pilot17_making_the_dataset/persps_of_claims_with_gt10_persps.json\"\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(data, fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
