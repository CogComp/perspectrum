{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27507 entries, 0 to 27506\n",
      "Data columns (total 12 columns):\n",
      "id                        27507 non-null int64\n",
      "claim_id                  27507 non-null int64\n",
      "perspective_id            27507 non-null int64\n",
      "vote_support              27507 non-null int64\n",
      "vote_leaning_support      27507 non-null int64\n",
      "vote_leaning_undermine    27507 non-null int64\n",
      "vote_undermine            27507 non-null int64\n",
      "vote_not_valid            27507 non-null int64\n",
      "p_i_5                     27507 non-null float64\n",
      "p_i_3                     27507 non-null float64\n",
      "label_3                   27507 non-null object\n",
      "label_5                   27507 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import query_elasticsearch as es\n",
    "\n",
    "# Claim \n",
    "re_step1_results = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_restep1results.csv\"\n",
    "claim = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_claim.csv\"\n",
    "perspective = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_perspective.csv\"\n",
    "\n",
    "re_step1_df = pd.read_csv(re_step1_results)\n",
    "claim_df = pd.read_csv(claim)\n",
    "perspective_df = pd.read_csv(perspective)\n",
    "perspective_df = perspective_df.dropna()\n",
    "\n",
    "re_step1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20797 entries, 0 to 20797\n",
      "Data columns (total 7 columns):\n",
      "id                       20797 non-null int64\n",
      "source                   20797 non-null object\n",
      "title                    20797 non-null object\n",
      "pilot1_high_agreement    20797 non-null int64\n",
      "similar_persps           20797 non-null object\n",
      "more_than_two_tokens     20797 non-null int64\n",
      "pilot1_have_stance       20797 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1006 entries, 0 to 1005\n",
      "Data columns (total 7 columns):\n",
      "id                          1006 non-null int64\n",
      "source                      1006 non-null object\n",
      "title                       1006 non-null object\n",
      "assignment_counts           1006 non-null int64\n",
      "finished_counts             1006 non-null int64\n",
      "evidence_assign_counts      1006 non-null int64\n",
      "evidence_finished_counts    1006 non-null int64\n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 55.1+ KB\n"
     ]
    }
   ],
   "source": [
    "perspective_df.info()\n",
    "claim_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5782 entries, 10 to 23602\n",
      "Data columns (total 12 columns):\n",
      "id                        5782 non-null int64\n",
      "claim_id                  5782 non-null int64\n",
      "perspective_id            5782 non-null int64\n",
      "vote_support              5782 non-null int64\n",
      "vote_leaning_support      5782 non-null int64\n",
      "vote_leaning_undermine    5782 non-null int64\n",
      "vote_undermine            5782 non-null int64\n",
      "vote_not_valid            5782 non-null int64\n",
      "p_i_5                     5782 non-null float64\n",
      "p_i_3                     5782 non-null float64\n",
      "label_3                   5782 non-null object\n",
      "label_5                   5782 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 587.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Filter out low quality ones and not-valid ones\n",
    "th = 0.5\n",
    "re_step1_df = re_step1_df[(re_step1_df[\"p_i_3\"] > th) & (re_step1_df.label_3.isin([\"S\", \"U\"]))]\n",
    "re_step1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make claim + persp data, for index\n",
    "def get_claim(claim_id):\n",
    "    q = claim_df[claim_df.id == claim_id]\n",
    "    if len(q) > 0:\n",
    "        return q.iloc[0].title\n",
    "    else:\n",
    "        print(\"Claim not found! cid = {}\".format(claim_id))\n",
    "        return None\n",
    "\n",
    "def get_perspective(perspective_id):\n",
    "    q = perspective_df[perspective_df.id == perspective_id]\n",
    "    if len(q) > 0:\n",
    "        p = q.iloc[0]\n",
    "        if p.pilot1_have_stance:\n",
    "            return p.title\n",
    "        else:\n",
    "            print(\"Perspective not valid! pid = {}\".format(perspective_id))\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Perspective not found! pid = {}\".format(perspective_id))\n",
    "        return None\n",
    "    \n",
    "def concat_claim_persp(claim, persp):\n",
    "    if not claim.endswith(\".\"):\n",
    "        try:\n",
    "            return claim + \". \" + persp\n",
    "        except TypeError:\n",
    "            print(claim, persp)\n",
    "    else:\n",
    "        return claim + \" \" + persp\n",
    "\n",
    "data = []\n",
    "for idx, row in re_step1_df.iterrows():\n",
    "    cid = row.claim_id\n",
    "    pid = row.perspective_id\n",
    "    claim_title = get_claim(cid)\n",
    "    persp_title = get_perspective(pid)\n",
    "    \n",
    "    if persp_title and claim_title:\n",
    "        c_p_concat = concat_claim_persp(claim_title, persp_title)\n",
    "        data.append({\n",
    "            \"claim_id\" : int(cid), \n",
    "            \"perspective_id\" : int(pid), \n",
    "            \"concat_title\" : c_p_concat\n",
    "        })\n",
    "\n",
    "# save data, for later usage\n",
    "import json\n",
    "\n",
    "out_path = \"/home/squirrel/ccg-new/projects/perspective/data/pilot12_evidence_verification/stance_claim_persp.json\"\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each claim + perspective pair in results, we index them in lucene (elastic search)\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['http://bronte.cs.illinois.edu'],port=8080)\n",
    "\n",
    "# Create indices \n",
    "index_name = \"re_step1_claim_persp_high_quality\"\n",
    "\n",
    "# es.indices.delete(index_name)\n",
    "es.indices.create(index_name)\n",
    "    \n",
    "for doc in data:\n",
    "    cpid = str(doc[\"claim_id\"]) + \"_\" + str(doc[\"perspective_id\"])\n",
    "    es.index(index=index_name, doc_type='text', id=cpid, body=doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import TransportError\n",
    "# For each evidence, retrieve the list of perspectives \n",
    "def get_top_re_step1_perspectives(text, num_cands=20):\n",
    "    res = es.search(index=\"re_step1_claim_persp_high_quality\", doc_type=\"text\", body={\"query\": {\"match\": {\"concat_title\": text}}}, size=num_cands)\n",
    "    # print(\"%d documents found:\" % res['hits']['total'])\n",
    "    output = []\n",
    "    for doc in res['hits']['hits']:\n",
    "        cid = doc['_source'][\"claim_id\"]\n",
    "        pid = doc['_source'][\"perspective_id\"]\n",
    "        score = doc['_score']\n",
    "        perspective_text = doc['_source'][\"concat_title\"]\n",
    "        output.append((perspective_text, cid, pid, score))\n",
    "\n",
    "    return output\n",
    "\n",
    "evidence_path = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_evidence.csv\"\n",
    "\n",
    "edf = pd.read_csv(evidence_path)\n",
    "\n",
    "result = []\n",
    "for idx, row in edf.iterrows():\n",
    "    print(\"Querying evidence: {}\".format(row.id))\n",
    "    try:\n",
    "        output = get_top_re_step1_perspectives(row.content)\n",
    "    except TransportError:\n",
    "        output = []\n",
    "        \n",
    "    result.append({\n",
    "        \"evidence_id\": row.id,\n",
    "        \"evidence_text\": row.content,\n",
    "        \"candidates\": output\n",
    "    })\n",
    "\n",
    "out_path = \"/home/squirrel/ccg-new/projects/perspective/data/pilot12_evidence_verification/perspective_candidates.json\"\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(result, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8092 entries, 0 to 8121\n",
      "Data columns (total 3 columns):\n",
      "id         8092 non-null int64\n",
      "source     8092 non-null object\n",
      "content    8092 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 252.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Index evidences\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['http://bronte.cs.illinois.edu'],port=8080, timeout=60)\n",
    "\n",
    "# Create indices \n",
    "index_name = \"evidences\"\n",
    "\n",
    "# es.indices.delete(index_name)\n",
    "es.indices.create(index_name)\n",
    "\n",
    "evidence_path = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_evidence.csv\"\n",
    "edf = pd.read_csv(evidence_path)\n",
    "edf = edf.dropna()\n",
    "edf.info()\n",
    "\n",
    "result = []\n",
    "for idx, row in edf.iterrows():\n",
    "    if row.content:\n",
    "        doc = {\n",
    "            \"id\" : row.id,\n",
    "            \"content\" : row.content\n",
    "        }\n",
    "        es.index(index=index_name, doc_type='text', id=row.id, body=doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(['http://bronte.cs.illinois.edu'],port=8080, timeout=30)\n",
    "cp_path = \"/home/squirrel/ccg-new/projects/perspective/data/pilot12_evidence_verification/stance_claim_persp.json\"\n",
    "\n",
    "def get_top_evidences(text, num_cands=50):\n",
    "    res = es.search(index=\"evidences\", doc_type=\"text\", body={\"query\": {\"match\": {\"content\": text}}}, size=num_cands)\n",
    "    # print(\"%d documents found:\" % res['hits']['total'])\n",
    "    output = []\n",
    "    for doc in res['hits']['hits']:\n",
    "        eid = doc['_source'][\"id\"]\n",
    "        score = doc['_score']\n",
    "        evidence = doc['_source'][\"content\"]\n",
    "        output.append((evidence, eid, score))\n",
    "\n",
    "    return output\n",
    "\n",
    "with open(cp_path) as fin:\n",
    "    cp_data = json.load(fin)\n",
    "\n",
    "# Evidence \n",
    "# For each claim + perspctive, find evidence candidates, \n",
    "persp_candidates = {}\n",
    "\n",
    "for cp in cp_data:\n",
    "    cid = cp[\"claim_id\"]\n",
    "    pid = cp[\"perspective_id\"]\n",
    "    \n",
    "    for evidence, eid, score in get_top_evidences(cp[\"concat_title\"]):\n",
    "        if eid not in persp_candidates:\n",
    "            persp_candidates[eid] = []\n",
    "        \n",
    "        token_len = len(cp[\"concat_title\"].split(\" \"))\n",
    "        persp_candidates[eid].append((cid, pid, score/token_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort \n",
    "for eid in persp_candidates:\n",
    "    persp_candidates[eid] = sorted(persp_candidates[eid], key=lambda trip: trip[2], reverse=True)\n",
    "\n",
    "out_path = \"/home/squirrel/ccg-new/projects/perspective/data/pilot12_evidence_verification/reverse_persp_candidates.json\"\n",
    "\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(persp_candidates, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 0.31815882650480526\n",
      "Top 5 accuracy: 0.650227617602428\n",
      "Top 20 accuracy: 0.8606474456246839\n",
      "Top 50 accuracy: 0.9001011633788568\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "valid_pids = perspective_df[(perspective_df.pilot1_have_stance == 1)].id.unique()\n",
    "\n",
    "er = \"/home/squirrel/ccg-new/projects/perspective/data/database_output/re-step1/webapp_evidencerelation.csv\"\n",
    "\n",
    "er_df = pd.read_csv(er)\n",
    "\n",
    "k = [1, 5, 20, 50]\n",
    "correct = {_k: 0 for _k in k}\n",
    "\n",
    "total = 0\n",
    "\n",
    "for eid in persp_candidates:\n",
    "    q = er_df[er_df.evidence_id == eid]\n",
    "    if len(q) == 0:\n",
    "        continue\n",
    "        \n",
    "    gold_pid = q.iloc[0].perspective_id\n",
    "    \n",
    "    if gold_pid in valid_pids:\n",
    "        total += 1\n",
    "        p_cands = [t[1] for t in persp_candidates[eid]]\n",
    "        p_cands = list(OrderedDict.fromkeys(p_cands))\n",
    "\n",
    "        for _k in k:\n",
    "            _cands = p_cands[:_k]\n",
    "            if gold_pid in _cands:\n",
    "                correct[_k] += 1\n",
    "\n",
    "for _k in correct:\n",
    "    print(\"Top {} accuracy: {}\".format(_k, correct[_k]/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 0.3212669683257919\n",
      "Top 5 accuracy: 0.5321769733534439\n",
      "Top 20 accuracy: 0.6759678230266466\n",
      "Top 50 accuracy: 0.6759678230266466\n"
     ]
    }
   ],
   "source": [
    "in_path = \"/home/squirrel/ccg-new/projects/perspective/data/pilot12_evidence_verification/perspective_candidates.json\"\n",
    "\n",
    "k = [1, 5, 20, 50]\n",
    "correct = {_k: 0 for _k in k}\n",
    "\n",
    "with open(in_path) as fin:\n",
    "    ev2pp = json.load(fin)\n",
    "    total = 0\n",
    "    for ev in ev2pp:\n",
    "        eid = ev[\"evidence_id\"]\n",
    "        gold_pid = er_df[er_df.evidence_id == eid].iloc[0].perspective_id\n",
    "        \n",
    "        if gold_pid in valid_pids:\n",
    "            total += 1\n",
    "            cands = [p[2] for p in ev[\"candidates\"]]\n",
    "\n",
    "            for _k in k:\n",
    "                _cands = cands[:_k]\n",
    "                if gold_pid in _cands:\n",
    "                    correct[_k] += 1\n",
    "            \n",
    "\n",
    "for _k in correct:\n",
    "    print(\"Top {} accuracy: {}\".format(_k, correct[_k]/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
