{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "human_test_set = [105,888,673,177,818,183,700,592,682,622,993,922,936,218,360,826,512,131,897,743]\n",
    "\n",
    "persp_data_path = \"../data/dataset/perspective_pool_v0.2.json\"\n",
    "claim_data_path = \"../data/dataset/perspectrum_with_answers_v0.2.json\"\n",
    "\n",
    "persps = json.load(open(persp_data_path))\n",
    "claims = json.load(open(claim_data_path))\n",
    "\n",
    "persp_dict = {}\n",
    "claim_dict = {}\n",
    "for p in persps:\n",
    "    persp_dict[p[\"pId\"]] = p[\"text\"]\n",
    "\n",
    "for c in claims:\n",
    "    claim_dict[c[\"cId\"]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make gold annotation\n",
    "data = []\n",
    "\n",
    "for cid in human_test_set:\n",
    "    cur_c = claim_dict[cid]\n",
    "    c_text = cur_c['text']\n",
    "    \n",
    "    p_clusters = [(p['pids'], p['stance_label_3']) for p in cur_c['perspectives']]\n",
    "    \n",
    "    p_title_clusters = []\n",
    "    for c, stance in p_clusters:\n",
    "        c = [(pid, persp_dict[pid]) for pid in c]\n",
    "        p_title_clusters.append((c, stance)) \n",
    "        \n",
    "    data.append({\n",
    "        \"claim_id\": cid,\n",
    "        \"claim_text\": c_text,\n",
    "        \"gold_perspectives\" : p_title_clusters\n",
    "    })\n",
    "    \n",
    "out_path = \"../data/dataset/human_eval/equivalence_human_eval_gold.json\"\n",
    "json.dump(data, open(out_path, 'w'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the table for stance annotation\n",
    "import csv\n",
    "\n",
    "out_path = \"../data/dataset/human_eval/stance_human_eval.csv\"\n",
    "\n",
    "f = open(out_path, 'w')\n",
    "fieldnames = ['claim_id', 'claim_title', 'perspective_id', 'perpsective_title', 'gold_stance']\n",
    "\n",
    "writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "\n",
    "for c in data:\n",
    "    \n",
    "    for clusters in c[\"gold_perspectives\"]:\n",
    "        stance = clusters[1]\n",
    "        for p, title in clusters[0]:\n",
    "            writer.writerow({\n",
    "                \"claim_id\": c[\"claim_id\"],\n",
    "                \"claim_title\": c[\"claim_text\"],\n",
    "                \"perspective_id\": p,\n",
    "                \"perpsective_title\": title,\n",
    "                \"gold_stance\": stance\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make spreadsheet for equivalence\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "out_path = \"../data/dataset/human_eval/equivalence_human_eval.csv\"\n",
    "\n",
    "f = open(out_path, 'w')\n",
    "fieldnames = ['claim_id', 'claim_title', 'perspective_id_1', 'perpsective_title_1', 'perspective_id_2', 'perpsective_title_2']\n",
    "\n",
    "writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "\n",
    "for c in data:\n",
    "    all_p = []\n",
    "\n",
    "    for clusters in c[\"gold_perspectives\"]:\n",
    "        for p, title in clusters[0]:\n",
    "            all_p.append((p, title))\n",
    "    \n",
    "    l_p = len(all_p)\n",
    "    \n",
    "    cartesian = list(itertools.combinations(all_p,2))\n",
    "        \n",
    "    for p1, p2 in cartesian:\n",
    "                \n",
    "        writer.writerow({\n",
    "            \"claim_id\": c[\"claim_id\"],\n",
    "            \"claim_title\": c[\"claim_text\"],\n",
    "            \"perspective_id_1\": p1[0],\n",
    "            \"perpsective_title_1\": p1[1],\n",
    "            \"perspective_id_2\": p2[0],\n",
    "            \"perpsective_title_2\": p2[1],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/squirrel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8695652173913043, 0.8333333333333334, 0.851063829787234)\n",
      "(0.8809523809523809, 0.7708333333333334, 0.8222222222222222)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how our two annotators, Rick and Daniel did!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def is_equivalent_in_gold(pid1, pid2, gold_clusters):\n",
    "    result = False\n",
    "    for c in gold_clusters:\n",
    "        if (pid1 in c) and (pid2 in c):\n",
    "            result = True\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def compute_p_r_f1(df):\n",
    "        \n",
    "    tp = fp = tn = fn = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        cid = row.claim_id\n",
    "        pid1 = row.perspective_id_1\n",
    "        pid2 = row.perspective_id_2\n",
    "        \n",
    "        \n",
    "        pred_eq = not df.isnull().ix[idx,'Equivalent']\n",
    "        gold_eq = is_equivalent_in_gold(pid1, pid2, gold_cluster_dict[cid])\n",
    "        \n",
    "        if pred_eq and gold_eq:\n",
    "            tp += 1\n",
    "        elif pred_eq and not gold_eq:\n",
    "            fp += 1\n",
    "        elif not pred_eq and gold_eq:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "            \n",
    "    \n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * prec * rec / (prec + rec)\n",
    "    return (prec, rec, f1)\n",
    "\n",
    "rick_result_path = '../data/dataset/human_eval/equivalence_rick.csv'\n",
    "daniel_result_path = '../data/dataset/human_eval/equivalence_daniel.csv'\n",
    "gold_path = '../data/dataset/human_eval/equivalence_human_eval_gold.json'\n",
    "\n",
    "rdf = pd.read_csv(rick_result_path)\n",
    "ddf = pd.read_csv(daniel_result_path)\n",
    "\n",
    "gold_data = json.load(open(gold_path))\n",
    "gold_cluster_dict = {}\n",
    "for data in gold_data:\n",
    "    clusters = []\n",
    "    for c in data[\"gold_perspectives\"]:\n",
    "        clusters.append([p[0] for p in c[0]])\n",
    "        \n",
    "    gold_cluster_dict[data['claim_id']] = clusters\n",
    "    \n",
    "# # We only got to row 718...\n",
    "rdf = rdf[rdf.index < 718]\n",
    "ddf = ddf[ddf.index < 718]\n",
    "\n",
    "\n",
    "print(compute_p_r_f1(rdf))\n",
    "print(compute_p_r_f1(ddf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
