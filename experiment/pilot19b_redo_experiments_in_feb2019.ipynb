{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "139\n",
      "227\n",
      "907\n",
      "0.596471885336\n",
      "0.153252480706\n",
      "0.250275633958\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "train_topics = [u'freedom_of_speech', \n",
    "                u'human_rights', u'law',  \n",
    "                u'world_international', \n",
    "                u'economy', u'culture', \n",
    "               ]\n",
    "\n",
    "dev_topics = [  \n",
    "    u'health_and_medicine', u'society',  u'science_and_technology',u'gender', u'education', \n",
    "]\n",
    "\n",
    "test_topics = [\n",
    "    u'politics',\n",
    "    u'digital_freedom', \n",
    "    u'sports_and_entertainments', \n",
    "    u'religion', \n",
    "    u'environment', \n",
    "    u'philosophy', \n",
    "    u'ethics'\n",
    "]\n",
    "\n",
    "split_id = {}\n",
    "\n",
    "total_train_size = 0; \n",
    "total_dev_size = 0; \n",
    "total_test_size = 0; \n",
    "for c in claims:\n",
    "    cId = c['cId']\n",
    "    topics = c['topics']\n",
    "    claim_text = c['text']\n",
    "#     for topic_text in topics:\n",
    "    train_int = len(intersection(topics, train_topics))\n",
    "    dev_int = len(intersection(topics, dev_topics))\n",
    "#     assert train_int == 0 or dev_int == 0 \n",
    "    if train_int > 0: \n",
    "        total_train_size += 1\n",
    "        split_id[cId] = \"train\"\n",
    "    elif dev_int > 0: \n",
    "        total_dev_size += 1\n",
    "        split_id[cId] = \"dev\"\n",
    "    else: \n",
    "        total_test_size += 1\n",
    "        split_id[cId] = \"test\"\n",
    "#         if topic_text in train_topics:\n",
    "#             total_train_size += 1\n",
    "#             break  \n",
    "\n",
    "print(total_train_size)\n",
    "print(total_dev_size)\n",
    "print(total_test_size)\n",
    "print(len(claims))\n",
    "print(total_train_size * 1.0 / len(claims))\n",
    "print(total_dev_size * 1.0 / len(claims))\n",
    "print(total_test_size * 1.0 / len(claims))\n",
    "print((total_train_size + total_test_size + total_dev_size)* 1.0 / len(claims))\n",
    "\n",
    "\n",
    "import json\n",
    "with open('/Users/daniel/ideaProjects/perspective/data/lucene_cach/dataset_split_v0.2.json', 'w') as outfile:\n",
    "    json.dump(split_id, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating clusters of claims that do not share any perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD: create stance training data\n",
    "\n",
    "# import json \n",
    "\n",
    "# with open('../data/dataset/perspectrum_with_answers_v0.1.json') as data:\n",
    "#     all_annotations = json.load(data)\n",
    "\n",
    "# with open('../data/dataset/perspective_pool_v0.1.json') as data:\n",
    "#     perspectives = json.load(data)\n",
    "\n",
    "# p_map = {}\n",
    "# for p in perspectives: \n",
    "#     p_map[p['pId']] = p['text']\n",
    "\n",
    "\n",
    "# # create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "# import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# def save_in_file(claims, file_name): \n",
    "#     with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "#         write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for c in claims: \n",
    "#             claim_text = c[\"text\"]\n",
    "#             for p in c[\"perspectives\"]:                \n",
    "#                 for pid in p[\"pids\"]: \n",
    "#                     if \"SUPPORT\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "#                         write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "#                     if \"UNDERMINE\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "# split_idx = int(0.7 * len(all_annotations))  \n",
    "        \n",
    "# save_in_file(all_annotations[0:split_idx], 'perspective_stances/train.tsv')\n",
    "# save_in_file(all_annotations[1 + split_idx:], 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stance training data\n",
    "\n",
    "import json \n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    p_map[p['pId']] = p['text']\n",
    "    \n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            claim_text = c[\"text\"]\n",
    "            for p in c[\"perspectives\"]:                \n",
    "                for pid in p[\"pids\"]: \n",
    "                    if \"SUPPORT\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "                        write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "                    if \"UNDERMINE\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_stances/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_stances/test.tsv')\n",
    "save_in_file(dev_claims, 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relevance training data\n",
    "\n",
    "import json \n",
    "import random\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            lucene_results = es.get_perspective_from_pool(claim_text, 50)\n",
    "            \n",
    "            rp = related_p_map[cid]\n",
    "            \n",
    "            if test_or_dev:\n",
    "                pid_set = [_pid for _text, _pid, _score in lucene_results]\n",
    "                for pid in pid_set:\n",
    "                    p_text = p_map[pid]\n",
    "                    if pid in rp:\n",
    "                        write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "                    else:\n",
    "                        write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "            else:            \n",
    "                for pid in rp:\n",
    "                    if pid in related_p_map[cid]:\n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "                        count += 1\n",
    "\n",
    "                for _text, pid, _score in lucene_results:\n",
    "                    if pid not in related_p_map[cid]:\n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "                        count -= 1\n",
    "                        if count <= 0:\n",
    "                            break\n",
    "                    \n",
    "\n",
    "# train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "# save_in_file(train_claims, 'perspective_relevance/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_relevance/test.tsv', test_or_dev=True)\n",
    "save_in_file(dev_claims, 'perspective_relevance/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2431 entries, 0 to 2430\n",
      "Data columns (total 6 columns):\n",
      "no_score     2431 non-null float64\n",
      "yes_score    2431 non-null float64\n",
      "cid          2431 non-null int64\n",
      "pid1         2431 non-null int64\n",
      "pid2         2431 non-null int64\n",
      "pred         2431 non-null int64\n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 114.0 KB\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate relevance\n",
    "####\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../data/dataset/perspective_relevance/eval_logits.out'\n",
    "test_data = '../data/dataset/perspective_relevance/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    test_ids.append([int(line[1]), int(line[2])])\n",
    "        \n",
    "\n",
    "rdf = pd.read_csv(raw_score, header=None, names=[\"no_score\", \"yes_score\"])\n",
    "rdf[\"cid\"] = rdf['pid1'] = rdf['pid2'] = rdf['pred'] = 0 \n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.no_score < row.yes_score else 0\n",
    "\n",
    "rdf.to_csv('../data/dataset/perspective_relevance/test_raw_score_w_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8281938325991189 0.23854238728422147 0.37039959885091006\n",
      "2 0.6299559471365639 0.33080962721140844 0.4338113221287824\n",
      "3 0.5411160058737156 0.38178773937049215 0.4476988151457768\n",
      "4 0.47687224669603523 0.42069362442754804 0.4470248263792118\n",
      "5 0.4396475770925107 0.44604423189787545 0.4428228054937776\n",
      "6 0.4126284875183554 0.4656845716456879 0.43755405536536485\n",
      "7 0.3937486889028739 0.47931865626830233 0.4323402851250338\n",
      "8 0.375734214390602 0.4905334969460526 0.42552715677907105\n",
      "9 0.36447626040137054 0.5013863813341453 0.42210721302990495\n",
      "10 0.3523861967694568 0.5074388657021872 0.41593216988530846\n",
      "11 0.34317514350553996 0.5133140962333826 0.4113458300818915\n",
      "12 0.3354992657856094 0.519189485685442 0.40760496953135283\n",
      "13 0.32736642945894057 0.5216121604513063 0.4022676485807741\n",
      "14 0.32039542689322426 0.5247126981391381 0.3978557155870366\n",
      "15 0.3143958464443046 0.5265136828502033 0.39370160336528587\n",
      "16 0.3083202223620726 0.5270031591106046 0.3890367127423959\n",
      "17 0.3037205851503597 0.5284587069375877 0.3857432868731467\n",
      "18 0.29987675687014903 0.5296710320407488 0.3829460663260359\n",
      "19 0.29714599457527824 0.5314698572977239 0.3811757619083484\n",
      "Best precision: 0.5411160058737156\n",
      "Best Recall: 0.38178773937049215\n",
      "Best F1: 0.4476988151457768\n",
      "Best # candidates: 3\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate relevance\n",
    "####\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "num_lucene_cands = [x for x in range(1, 20)]\n",
    "\n",
    "best_param = -1\n",
    "best_p = -1\n",
    "best_r = -1\n",
    "best_f1 = -1\n",
    "\n",
    "for num_c in num_lucene_cands:\n",
    "    tot_p = tot_r = tot_count = 0\n",
    "    for cid in unique_cids:\n",
    "        claim = claim_map[cid]\n",
    "        covered = [False for _c in claim[\"perspectives\"]]\n",
    "        \n",
    "        cdf = rdf[rdf.cid == cid].head(num_c)\n",
    "\n",
    "        for idx, row in cdf.iterrows():\n",
    "            \n",
    "            pid = row.pid\n",
    "            \n",
    "            for idx, clus in enumerate(claim[\"perspectives\"]):\n",
    "                if pid in clus[\"pids\"]:\n",
    "                    covered[idx] = True\n",
    "\n",
    "        tot_pred = len(cdf.index)\n",
    "        tot_gold = len(covered)\n",
    "        hit = [h for h in covered if h]\n",
    "        \n",
    "        if tot_pred == 0:\n",
    "            tot_p += 1\n",
    "        else:\n",
    "            tot_p += len(hit) / tot_pred\n",
    "\n",
    "        if tot_gold == 0:\n",
    "            tot_r += 1\n",
    "        else:\n",
    "            tot_r += len(hit) / tot_gold\n",
    "\n",
    "\n",
    "    mean_p = tot_p / len(unique_cids)\n",
    "    mean_r = tot_r / len(unique_cids)\n",
    "    mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "    print(num_c, mean_p, mean_r, mean_f1)\n",
    "    if mean_f1 > best_f1:\n",
    "        best_f1 = mean_f1\n",
    "        best_p = mean_p\n",
    "        best_r = mean_r\n",
    "        best_param = num_c\n",
    "\n",
    "print(\"Best precision: {}\".format(best_p))\n",
    "print(\"Best Recall: {}\".format(best_r))\n",
    "print(\"Best F1: {}\".format(best_f1))\n",
    "print(\"Best # candidates: {}\".format(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GET http://bronte.cs.illinois.edu:8080/evidence_pool_v0.2/text/_search?size=20 [status:N/A request:0.027s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 383, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 1331, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 297, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 266, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/elasticsearch/connection/http_urllib3.py\", line 172, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=Retry(False), headers=request_headers, **kw)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/util/retry.py\", line 333, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 383, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 1331, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 297, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 266, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n"
     ]
    }
   ],
   "source": [
    "# Create Evidence training data\n",
    "\n",
    "import json \n",
    "import random\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/evidence_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    evidences = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "    \n",
    "e_map = {}\n",
    "for e in evidences: \n",
    "    e_map[e[\"eId\"]] = e['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            \n",
    "            for cluster in c[\"perspectives\"]:\n",
    "                for pid in cluster[\"pids\"]:\n",
    "                    p_text = p_map[pid]\n",
    "                    c_p_text = claim_text + '. ' + p_text\n",
    "                    lucene_results = es.get_evidence_from_pool(c_p_text, 20)\n",
    "                    \n",
    "                    if test_or_dev:\n",
    "                        for e_text, _eid, _score in lucene_results:\n",
    "                            if _eid in cluster['evidence']:\n",
    "                                write.writerow([str(1), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                            else:\n",
    "                                write.writerow([str(0), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                    else:\n",
    "                        for eid in cluster[\"evidence\"]:\n",
    "                            write.writerow([str(1), str(cid) + '-' + str(pid), str(eid), c_p_text, e_map[eid]])\n",
    "                            count += 1\n",
    "                        \n",
    "                        for e_text, _eid, _score in lucene_results:\n",
    "                            if _eid not in cluster['evidence']:\n",
    "                                if count <= 0 and not test_or_dev:\n",
    "                                    break\n",
    "                                write.writerow([str(0), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                                count -= 1\n",
    "                            \n",
    "                    \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "# test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "# dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_evidence/train.tsv', test_or_dev=True)\n",
    "# save_in_file(test_claims, 'perspective_evidence/test.tsv', test_or_dev=True)\n",
    "# save_in_file(dev_claims, 'perspective_evidence/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/dataset/perspective_evidence/test.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-4673c6b15139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpid_cid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/dataset/perspective_evidence/test.tsv'"
     ]
    }
   ],
   "source": [
    "# Evaluate BERT results on evidence discovery\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../data/dataset/perspective_evidence/test_raw_score.csv'\n",
    "test_data = '../data/dataset/perspective_evidence/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    pid_cid = [int(x) for x in line[1].split('-')]\n",
    "    pid_cid.append(int(line[2]))\n",
    "    pid_cid.append(line[3])\n",
    "    pid_cid.append(line[4])\n",
    "    test_ids.append(pid_cid)\n",
    "        \n",
    "test_ids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "rdf = pd.read_csv(raw_score)\n",
    "rdf[\"cid\"] = rdf['pid'] = rdf['eid'] = rdf['pred'] = 0 \n",
    "rdf[\"c_p_text\"] = rdf[\"e_text\"] = \"\"\n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'eid'] = test_ids[idx][2]\n",
    "    rdf.at[idx, \"c_p_text\"] = test_ids[idx][3]\n",
    "    rdf.at[idx, \"e_text\"] = test_ids[idx][4]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.undermine_score < row.support_score else 0\n",
    "    \n",
    "rdf.to_csv('../data/dataset/perspective_evidence/test_raw_score_w_id.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "3 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "4 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "5 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "6 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "7 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "8 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "9 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "10 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "11 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "12 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "13 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "14 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "15 0.7678524141583547 0.9460445549144916 0.8476852558825935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-5f84e67ebe44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_gold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   3970\u001b[0m         \"\"\"\n\u001b[1;32m   3971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0mslice_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, obj, axis, kind)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \"\"\"\n\u001b[1;32m   2589\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   3880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3881\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3882\u001b[0;31m         \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3884\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;31m# This case is separated from the conditional above to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m             \u001b[0;31m# pessimization of basic indexing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2089\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpromote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Ensure we are not returning an Int64Index with float data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         return (super(NumericIndex, self)._shallow_copy(values=values,\n\u001b[1;32m     70\u001b[0m                                                         **kwargs))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             if (is_datetime64_any_dtype(data) or\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_datetime64_any_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     'tz' in kwargs):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64_any_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m     return (is_datetime64_dtype(arr_or_dtype) or\n\u001b[0m\u001b[1;32m   1080\u001b[0m             is_datetime64tz_dtype(arr_or_dtype))\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtipo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate BERT results on evidence discovery, cont...\n",
    "\n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "num_lucene_cands = [x for x in range(1, 20)]\n",
    "\n",
    "best_param = -1\n",
    "best_p = -1\n",
    "best_r = -1\n",
    "best_f1 = -1\n",
    "\n",
    "for num_c in num_lucene_cands:\n",
    "    tot_p = tot_r = tot_count = 0\n",
    "    for cid in unique_cids:\n",
    "        cdf = rdf[rdf.cid == cid]\n",
    "        \n",
    "        unique_pids = cdf.pid.unique()\n",
    "        for pid in unique_pids:\n",
    "            \n",
    "            tp = tot_pred = tot_gold = 0\n",
    "            pdf = cdf[cdf.pid == pid].head(num_c)\n",
    "            \n",
    "            for idx, row in pdf.iterrows():\n",
    "\n",
    "                if row.pred == 1:\n",
    "                    tot_pred += 1\n",
    "                    if row.gold == 1:\n",
    "                        tp += 1\n",
    "                pid = row.pid\n",
    "\n",
    "                for cluster in claim_map[cid][\"perspectives\"]:\n",
    "                    if pid in cluster[\"pids\"]:\n",
    "                        tot_gold = len(cluster[\"evidence\"])\n",
    "                        break\n",
    "\n",
    "            if tot_pred == 0:\n",
    "                tot_p += 1\n",
    "            else:\n",
    "                tot_p += tp / tot_pred\n",
    "\n",
    "            if tot_gold == 0:\n",
    "                tot_r += 1\n",
    "            else:\n",
    "                tot_r += tp / tot_gold\n",
    "\n",
    "            tot_count += 1\n",
    "\n",
    "\n",
    "    mean_p = tot_p / tot_count\n",
    "    mean_r = tot_r / tot_count\n",
    "    mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "    print(num_c, mean_p, mean_r, mean_f1)\n",
    "    if mean_f1 > best_f1:\n",
    "        best_f1 = mean_f1\n",
    "        best_p = mean_p\n",
    "        best_r = mean_r\n",
    "        best_param = num_c\n",
    "\n",
    "print(\"Best precision: {}\".format(best_p))\n",
    "print(\"Best Recall: {}\".format(best_r))\n",
    "print(\"Best F1: {}\".format(best_f1))\n",
    "print(\"Best # candidates: {}\".format(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "# Create equivalence training data\n",
    "#####\n",
    "\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            \n",
    "            pairs = list(combinations(related_p_map[cid], 2))\n",
    "            \n",
    "            if test_or_dev:\n",
    "                for p1, p2 in pairs:\n",
    "                    p1_text = p_map[p1]\n",
    "                    p2_text = p_map[p2]\n",
    "                    same_cluster = False\n",
    "                    for cluster in c[\"perspectives\"]:\n",
    "                        if (p1 in cluster[\"pids\"]) and (p2 in cluster[\"pids\"]):\n",
    "                            same_cluster = True\n",
    "                            break\n",
    "                    \n",
    "                    if same_cluster:\n",
    "                        write.writerow([str(1), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                    else:\n",
    "                        write.writerow([str(0), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "            else:\n",
    "                counter = 0\n",
    "                for p1, p2 in pairs:\n",
    "                    p1_text = p_map[p1]\n",
    "                    p2_text = p_map[p2]\n",
    "                    same_cluster = False\n",
    "                    for cluster in c[\"perspectives\"]:\n",
    "                        if (p1 in cluster[\"pids\"]) and (p2 in cluster[\"pids\"]):\n",
    "                            same_cluster = True\n",
    "                            break\n",
    "                    \n",
    "                    if same_cluster:\n",
    "                        write.writerow([str(1), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                        counter += 1\n",
    "                    elif counter > 0:\n",
    "                        write.writerow([str(0), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                        counter -= 1\n",
    "\n",
    "            \n",
    "#             if test_or_dev:\n",
    "#                 pid_set = [_pid for _text, _pid, _score in lucene_results]\n",
    "#             else:\n",
    "#                 pid_set = related_p_map[cid]\n",
    "                \n",
    "#             for pid in pid_set:\n",
    "#                 if pid in related_p_map[cid]:\n",
    "#                     p_text = p_map[pid]\n",
    "#                     write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "#                     count += 1\n",
    "            \n",
    "#             for _text, pid, _score in lucene_results:\n",
    "#                 if pid not in related_p_map[cid]:\n",
    "#                     p_text = p_map[pid]\n",
    "#                     write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "#                     count -= 1\n",
    "#                     if count <= 0:\n",
    "#                         break\n",
    "                    \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_equivalence/train.tsv', test_or_dev=True)\n",
    "save_in_file(test_claims, 'perspective_equivalence/test.tsv', test_or_dev=True)\n",
    "save_in_file(dev_claims, 'perspective_equivalence/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33571 entries, 0 to 33570\n",
      "Data columns (total 7 columns):\n",
      "undermine_score    33571 non-null float64\n",
      "support_score      33571 non-null float64\n",
      "cid                33571 non-null int64\n",
      "pid1               33571 non-null int64\n",
      "pid2               33571 non-null int64\n",
      "pred               33571 non-null int64\n",
      "gold               33571 non-null int64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate equivalence\n",
    "####\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../result/lr3e-05_bs32_equivalence_eval_logits.out'\n",
    "test_data = '../data/dataset/perspective_equivalence/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    pid_cid = [int(x) for x in line[1].split('-')]\n",
    "    pid_cid.append(int(line[2]))\n",
    "    pid_cid.append(int(line[0]))\n",
    "    test_ids.append(pid_cid)\n",
    "        \n",
    "# test_ids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "rdf = pd.read_csv(raw_score, header=None, names=[\"undermine_score\", \"support_score\"])\n",
    "rdf[\"cid\"] = rdf['pid1'] = rdf['pid2'] = rdf['pred'] = rdf['gold'] = 0 \n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid1'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'pid2'] = test_ids[idx][2]\n",
    "    rdf.at[idx, 'gold'] = test_ids[idx][3]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.undermine_score < row.support_score else 0\n",
    "    \n",
    "rdf.to_csv('../data/dataset/perspective_equivalence/test_raw_score_w_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7626610615157229\n",
      "Recall: 0.7431619325662322\n",
      "F1: 0.7527852484608711\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate equivalence cont.\n",
    "####\n",
    "\n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "tot_p = tot_r = 0\n",
    "for cid in unique_cids:\n",
    "    cdf = rdf[rdf.cid == cid]\n",
    "    tp = tot_pred = tot_gold = 0\n",
    "    for idx, row in cdf.iterrows():\n",
    "        if row.gold == 1:\n",
    "            tot_gold += 1\n",
    "\n",
    "        if row.pred == 1:\n",
    "            tot_pred += 1\n",
    "            if row.gold == 1:\n",
    "                tp += 1\n",
    "\n",
    "    if tot_gold == 0:\n",
    "        tot_p += 1\n",
    "    else:\n",
    "        tot_p += tp / tot_gold\n",
    "\n",
    "    if tot_pred == 0:\n",
    "        tot_r += 1\n",
    "    else:\n",
    "        tot_r += tp / tot_pred\n",
    "\n",
    "mean_p = tot_p / len(unique_cids)\n",
    "mean_r = tot_r / len(unique_cids)\n",
    "mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "\n",
    "print(\"Precision: {}\".format(mean_p))\n",
    "print(\"Recall: {}\".format(mean_r))\n",
    "print(\"F1: {}\".format(mean_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evidence Discovery Task\n",
    "\n",
    "Making training data for \n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "with open('../data/dataset/evidence_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    evidences = json.load(data)\n",
    "    \n",
    "# First split the evidence into batches of 3 sentences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New BERT baseline results\n",
    "\n",
    "| Task        | P | R | F1 |\n",
    "|-------------|---|---|----|\n",
    "| Relevance   | ~54.1  | ~38.2  | ~44.3   |\n",
    "| Stance      | 78.3 | 76.7 | 77.5 |\n",
    "| Equivalence | 76.3 | 74.3 | 75.3 |\n",
    "| Evidence    | ~60.2 | ~37.9 | ~46.5 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
