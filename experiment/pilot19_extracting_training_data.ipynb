{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "139\n",
      "227\n",
      "907\n",
      "0.596471885336\n",
      "0.153252480706\n",
      "0.250275633958\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "train_topics = [u'freedom_of_speech', \n",
    "                u'human_rights', u'law',  \n",
    "                u'world_international', \n",
    "                u'economy', u'culture', \n",
    "               ]\n",
    "\n",
    "dev_topics = [  \n",
    "    u'health_and_medicine', u'society',  u'science_and_technology',u'gender', u'education', \n",
    "]\n",
    "\n",
    "test_topics = [\n",
    "    u'politics',\n",
    "    u'digital_freedom', \n",
    "    u'sports_and_entertainments', \n",
    "    u'religion', \n",
    "    u'environment', \n",
    "    u'philosophy', \n",
    "    u'ethics'\n",
    "]\n",
    "\n",
    "split_id = {}\n",
    "\n",
    "total_train_size = 0; \n",
    "total_dev_size = 0; \n",
    "total_test_size = 0; \n",
    "for c in claims:\n",
    "    cId = c['cId']\n",
    "    topics = c['topics']\n",
    "    claim_text = c['text']\n",
    "#     for topic_text in topics:\n",
    "    train_int = len(intersection(topics, train_topics))\n",
    "    dev_int = len(intersection(topics, dev_topics))\n",
    "#     assert train_int == 0 or dev_int == 0 \n",
    "    if train_int > 0: \n",
    "        total_train_size += 1\n",
    "        split_id[cId] = \"train\"\n",
    "    elif dev_int > 0: \n",
    "        total_dev_size += 1\n",
    "        split_id[cId] = \"dev\"\n",
    "    else: \n",
    "        total_test_size += 1\n",
    "        split_id[cId] = \"test\"\n",
    "#         if topic_text in train_topics:\n",
    "#             total_train_size += 1\n",
    "#             break  \n",
    "\n",
    "print(total_train_size)\n",
    "print(total_dev_size)\n",
    "print(total_test_size)\n",
    "print(len(claims))\n",
    "print(total_train_size * 1.0 / len(claims))\n",
    "print(total_dev_size * 1.0 / len(claims))\n",
    "print(total_test_size * 1.0 / len(claims))\n",
    "print((total_train_size + total_test_size + total_dev_size)* 1.0 / len(claims))\n",
    "\n",
    "\n",
    "import json\n",
    "with open('/Users/daniel/ideaProjects/perspective/data/lucene_cach/dataset_split_v0.2.json', 'w') as outfile:\n",
    "    json.dump(split_id, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating clusters of claims that do not share any perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD: create stance training data\n",
    "\n",
    "# import json \n",
    "\n",
    "# with open('../data/dataset/perspectrum_with_answers_v0.1.json') as data:\n",
    "#     all_annotations = json.load(data)\n",
    "\n",
    "# with open('../data/dataset/perspective_pool_v0.1.json') as data:\n",
    "#     perspectives = json.load(data)\n",
    "\n",
    "# p_map = {}\n",
    "# for p in perspectives: \n",
    "#     p_map[p['pId']] = p['text']\n",
    "\n",
    "\n",
    "# # create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "# import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# def save_in_file(claims, file_name): \n",
    "#     with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "#         write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for c in claims: \n",
    "#             claim_text = c[\"text\"]\n",
    "#             for p in c[\"perspectives\"]:                \n",
    "#                 for pid in p[\"pids\"]: \n",
    "#                     if \"SUPPORT\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "#                         write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "#                     if \"UNDERMINE\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "# split_idx = int(0.7 * len(all_annotations))  \n",
    "        \n",
    "# save_in_file(all_annotations[0:split_idx], 'perspective_stances/train.tsv')\n",
    "# save_in_file(all_annotations[1 + split_idx:], 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stance training data\n",
    "\n",
    "import json \n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    p_map[p['pId']] = p['text']\n",
    "    \n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            claim_text = c[\"text\"]\n",
    "            for p in c[\"perspectives\"]:                \n",
    "                for pid in p[\"pids\"]: \n",
    "                    if \"SUPPORT\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "                        write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "                    if \"UNDERMINE\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_stances/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_stances/test.tsv')\n",
    "save_in_file(dev_claims, 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relevance training data\n",
    "\n",
    "import json \n",
    "import random\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            lucene_results = es.get_perspective_from_pool(claim_text, 50)\n",
    "            \n",
    "            rp = related_p_map[cid]\n",
    "            \n",
    "            if test_or_dev:\n",
    "                pid_set = [_pid for _text, _pid, _score in lucene_results]\n",
    "                for pid in pid_set:\n",
    "                    p_text = p_map[pid]\n",
    "                    if pid in rp:\n",
    "                        write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "                    else:\n",
    "                        write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "            else:            \n",
    "                for pid in rp:\n",
    "                    if pid in related_p_map[cid]:\n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "                        count += 1\n",
    "\n",
    "                for _text, pid, _score in lucene_results:\n",
    "                    if pid not in related_p_map[cid]:\n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "                        count -= 1\n",
    "                        if count <= 0:\n",
    "                            break\n",
    "                    \n",
    "\n",
    "# train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "# save_in_file(train_claims, 'perspective_relevance/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_relevance/test.tsv', test_or_dev=True)\n",
    "save_in_file(dev_claims, 'perspective_relevance/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11329 entries, 0 to 11328\n",
      "Data columns (total 7 columns):\n",
      "undermine_score    11329 non-null float64\n",
      "support_score      11329 non-null float64\n",
      "gold               11329 non-null int64\n",
      "cid                11329 non-null int64\n",
      "pid1               11329 non-null int64\n",
      "pid2               11329 non-null int64\n",
      "pred               11329 non-null int64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 619.6 KB\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate relevance\n",
    "####\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../data/dataset/perspective_relevance/test_raw_score.csv'\n",
    "test_data = '../data/dataset/perspective_relevance/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    test_ids.append([int(line[1]), int(line[2])])\n",
    "        \n",
    "test_ids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "rdf = pd.read_csv(raw_score)\n",
    "rdf[\"cid\"] = rdf['pid1'] = rdf['pid2'] = rdf['pred'] = 0 \n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.undermine_score < row.support_score else 0\n",
    "\n",
    "rdf.to_csv('../data/dataset/perspective_relevance/test_raw_score_w_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.4801762114537445 0.1257958953663458 0.19936296002276965\n",
      "2 0.3788546255506608 0.18722930930552217 0.2506083833206583\n",
      "3 0.3201174743024965 0.22503538818305396 0.26428462565671845\n",
      "4 0.2841409691629956 0.26237234939925863 0.27282311741643406\n",
      "5 0.2581497797356831 0.29179504323562666 0.27394321391101045\n",
      "6 0.23788546255506585 0.3187080671556472 0.272428664468152\n",
      "7 0.21900566393958476 0.3370495270032922 0.26549794568669727\n",
      "8 0.20319383259911894 0.3521991547850443 0.2577083172619983\n",
      "9 0.1908957415565345 0.36602837454776205 0.25092559639468964\n",
      "10 0.17753303964757722 0.37461994592046016 0.24090213926290582\n",
      "11 0.16659991990388476 0.382675093939943 0.23213741165270915\n",
      "12 0.157856093979442 0.3916519175312699 0.225018163906568\n",
      "13 0.1497797356828192 0.39845231989331226 0.21771832766367244\n",
      "14 0.1412838263058528 0.40193246245093606 0.2090753071545926\n",
      "15 0.13538913362701888 0.4107067357432192 0.20364640073611914\n",
      "16 0.1296806167400881 0.4159176770638699 0.19771491768677582\n",
      "17 0.12334801762114511 0.42083691348090363 0.1907785241849575\n",
      "18 0.11796377875673032 0.4239494066426323 0.18457079604875543\n",
      "19 0.11314630187804313 0.4315941358732647 0.17929008754295414\n",
      "20 0.10969162995594725 0.4404191049210894 0.17563841757544393\n",
      "21 0.10530732116635177 0.44464083766705126 0.17028490683633446\n",
      "22 0.10152182619142977 0.4524770581742664 0.16583534209882866\n",
      "23 0.09902317563685109 0.46410029742703884 0.16322063442032517\n",
      "24 0.09618208516886925 0.46799379315131967 0.15956945555845345\n",
      "25 0.09339207048458127 0.4710665196879924 0.15587991174402002\n",
      "26 0.09030837004405279 0.472646987678152 0.15164250052135816\n",
      "27 0.0879425681187795 0.4778985276213219 0.14854920978912564\n",
      "28 0.08527375707992454 0.4804368116574032 0.14483962023537708\n",
      "29 0.08324472125170898 0.48355657876975094 0.14203754510652647\n",
      "30 0.0809104258443465 0.48465481542123967 0.13867057111040232\n",
      "31 0.0787598882099381 0.48869299456955106 0.13565674539443523\n",
      "32 0.07715675477239355 0.4926437672427907 0.13341789931981562\n",
      "33 0.07565078093712467 0.4973096838029803 0.13132447441851083\n",
      "34 0.07371512481644629 0.500062987767738 0.1284894099336195\n",
      "35 0.07189007761694972 0.5013216410087701 0.12574778397616654\n",
      "36 0.06992168379833584 0.5013216410087701 0.12272617198884428\n",
      "37 0.06865499861094573 0.5089753632906344 0.12098984113192446\n",
      "38 0.06710719530102792 0.5102340165316664 0.1186139949646998\n",
      "39 0.06654241500056463 0.5149795440803473 0.11785619443556745\n",
      "40 0.06534508076358304 0.51795835675079 0.11604948120409163\n",
      "41 0.06431359908312727 0.5203194356595156 0.11447733395666189\n",
      "42 0.06312146003775947 0.5227812133221225 0.11264230380097547\n",
      "43 0.06177987228084562 0.523662270590845 0.11052087243569159\n",
      "44 0.06079962621812845 0.525824865704982 0.10899631955786407\n",
      "Best precision: 0.2581497797356831\n",
      "Best Recall: 0.29179504323562666\n",
      "Best F1: 0.27394321391101045\n",
      "Best # candidates: 5\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate relevance\n",
    "####\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "num_lucene_cands = [x for x in range(1, 45)]\n",
    "\n",
    "best_param = -1\n",
    "best_p = -1\n",
    "best_r = -1\n",
    "best_f1 = -1\n",
    "\n",
    "for num_c in num_lucene_cands:\n",
    "    tot_p = tot_r = tot_count = 0\n",
    "    for cid in unique_cids:\n",
    "        claim = claim_map[cid]\n",
    "        covered = [False for _c in claim[\"perspectives\"]]\n",
    "        \n",
    "        cdf = rdf[rdf.cid == cid].head(num_c)\n",
    "\n",
    "        for idx, row in cdf.iterrows():\n",
    "            \n",
    "            pid = row.pid\n",
    "            \n",
    "            for idx, clus in enumerate(claim[\"perspectives\"]):\n",
    "                if pid in clus[\"pids\"]:\n",
    "                    covered[idx] = True\n",
    "\n",
    "        tot_pred = len(cdf.index)\n",
    "        tot_gold = len(covered)\n",
    "        hit = [h for h in covered if h]\n",
    "        \n",
    "        if tot_pred == 0:\n",
    "            tot_p += 1\n",
    "        else:\n",
    "            tot_p += len(hit) / tot_pred\n",
    "\n",
    "        if tot_gold == 0:\n",
    "            tot_r += 1\n",
    "        else:\n",
    "            tot_r += len(hit) / tot_gold\n",
    "\n",
    "\n",
    "    mean_p = tot_p / len(unique_cids)\n",
    "    mean_r = tot_r / len(unique_cids)\n",
    "    mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "    print(num_c, mean_p, mean_r, mean_f1)\n",
    "    if mean_f1 > best_f1:\n",
    "        best_f1 = mean_f1\n",
    "        best_p = mean_p\n",
    "        best_r = mean_r\n",
    "        best_param = num_c\n",
    "\n",
    "print(\"Best precision: {}\".format(best_p))\n",
    "print(\"Best Recall: {}\".format(best_r))\n",
    "print(\"Best F1: {}\".format(best_f1))\n",
    "print(\"Best # candidates: {}\".format(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GET http://bronte.cs.illinois.edu:8080/evidence_pool_v0.2/text/_search?size=20 [status:N/A request:0.027s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 383, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 1331, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 297, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 266, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/elasticsearch/connection/http_urllib3.py\", line 172, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=Retry(False), headers=request_headers, **kw)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/util/retry.py\", line 333, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 383, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 1331, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 297, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/squirrel/anaconda3/lib/python3.6/http/client.py\", line 266, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n"
     ]
    }
   ],
   "source": [
    "# Create Evidence training data\n",
    "\n",
    "import json \n",
    "import random\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/evidence_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    evidences = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "    \n",
    "e_map = {}\n",
    "for e in evidences: \n",
    "    e_map[e[\"eId\"]] = e['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            \n",
    "            for cluster in c[\"perspectives\"]:\n",
    "                for pid in cluster[\"pids\"]:\n",
    "                    p_text = p_map[pid]\n",
    "                    c_p_text = claim_text + '. ' + p_text\n",
    "                    lucene_results = es.get_evidence_from_pool(c_p_text, 20)\n",
    "                    \n",
    "                    if test_or_dev:\n",
    "                        for e_text, _eid, _score in lucene_results:\n",
    "                            if _eid in cluster['evidence']:\n",
    "                                write.writerow([str(1), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                            else:\n",
    "                                write.writerow([str(0), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                    else:\n",
    "                        for eid in cluster[\"evidence\"]:\n",
    "                            write.writerow([str(1), str(cid) + '-' + str(pid), str(eid), c_p_text, e_map[eid]])\n",
    "                            count += 1\n",
    "                        \n",
    "                        for e_text, _eid, _score in lucene_results:\n",
    "                            if _eid not in cluster['evidence']:\n",
    "                                if count <= 0 and not test_or_dev:\n",
    "                                    break\n",
    "                                write.writerow([str(0), str(cid) + '-' + str(pid), str(_eid), c_p_text, e_text])\n",
    "                                count -= 1\n",
    "                            \n",
    "                    \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "# test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "# dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_evidence/train.tsv', test_or_dev=True)\n",
    "# save_in_file(test_claims, 'perspective_evidence/test.tsv', test_or_dev=True)\n",
    "# save_in_file(dev_claims, 'perspective_evidence/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/dataset/perspective_evidence/test.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-4673c6b15139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpid_cid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/dataset/perspective_evidence/test.tsv'"
     ]
    }
   ],
   "source": [
    "# Evaluate BERT results on evidence discovery\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../data/dataset/perspective_evidence/test_raw_score.csv'\n",
    "test_data = '../data/dataset/perspective_evidence/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    pid_cid = [int(x) for x in line[1].split('-')]\n",
    "    pid_cid.append(int(line[2]))\n",
    "    pid_cid.append(line[3])\n",
    "    pid_cid.append(line[4])\n",
    "    test_ids.append(pid_cid)\n",
    "        \n",
    "test_ids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "rdf = pd.read_csv(raw_score)\n",
    "rdf[\"cid\"] = rdf['pid'] = rdf['eid'] = rdf['pred'] = 0 \n",
    "rdf[\"c_p_text\"] = rdf[\"e_text\"] = \"\"\n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'eid'] = test_ids[idx][2]\n",
    "    rdf.at[idx, \"c_p_text\"] = test_ids[idx][3]\n",
    "    rdf.at[idx, \"e_text\"] = test_ids[idx][4]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.undermine_score < row.support_score else 0\n",
    "    \n",
    "rdf.to_csv('../data/dataset/perspective_evidence/test_raw_score_w_id.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "3 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "4 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "5 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "6 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "7 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "8 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "9 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "10 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "11 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "12 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "13 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "14 0.7678524141583547 0.9460445549144916 0.8476852558825935\n",
      "15 0.7678524141583547 0.9460445549144916 0.8476852558825935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-5f84e67ebe44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_gold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   3970\u001b[0m         \"\"\"\n\u001b[1;32m   3971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0mslice_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, obj, axis, kind)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \"\"\"\n\u001b[1;32m   2589\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   3880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3881\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3882\u001b[0;31m         \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3884\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;31m# This case is separated from the conditional above to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m             \u001b[0;31m# pessimization of basic indexing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2089\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpromote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Ensure we are not returning an Int64Index with float data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         return (super(NumericIndex, self)._shallow_copy(values=values,\n\u001b[1;32m     70\u001b[0m                                                         **kwargs))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             if (is_datetime64_any_dtype(data) or\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_datetime64_any_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     'tz' in kwargs):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64_any_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m     return (is_datetime64_dtype(arr_or_dtype) or\n\u001b[0m\u001b[1;32m   1080\u001b[0m             is_datetime64tz_dtype(arr_or_dtype))\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtipo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate BERT results on evidence discovery, cont...\n",
    "\n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "num_lucene_cands = [x for x in range(1, 20)]\n",
    "\n",
    "best_param = -1\n",
    "best_p = -1\n",
    "best_r = -1\n",
    "best_f1 = -1\n",
    "\n",
    "for num_c in num_lucene_cands:\n",
    "    tot_p = tot_r = tot_count = 0\n",
    "    for cid in unique_cids:\n",
    "        cdf = rdf[rdf.cid == cid]\n",
    "        \n",
    "        unique_pids = cdf.pid.unique()\n",
    "        for pid in unique_pids:\n",
    "            \n",
    "            tp = tot_pred = tot_gold = 0\n",
    "            pdf = cdf[cdf.pid == pid].head(num_c)\n",
    "            \n",
    "            for idx, row in pdf.iterrows():\n",
    "\n",
    "                if row.pred == 1:\n",
    "                    tot_pred += 1\n",
    "                    if row.gold == 1:\n",
    "                        tp += 1\n",
    "                pid = row.pid\n",
    "\n",
    "                for cluster in claim_map[cid][\"perspectives\"]:\n",
    "                    if pid in cluster[\"pids\"]:\n",
    "                        tot_gold = len(cluster[\"evidence\"])\n",
    "                        break\n",
    "\n",
    "            if tot_pred == 0:\n",
    "                tot_p += 1\n",
    "            else:\n",
    "                tot_p += tp / tot_pred\n",
    "\n",
    "            if tot_gold == 0:\n",
    "                tot_r += 1\n",
    "            else:\n",
    "                tot_r += tp / tot_gold\n",
    "\n",
    "            tot_count += 1\n",
    "\n",
    "\n",
    "    mean_p = tot_p / tot_count\n",
    "    mean_r = tot_r / tot_count\n",
    "    mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "    print(num_c, mean_p, mean_r, mean_f1)\n",
    "    if mean_f1 > best_f1:\n",
    "        best_f1 = mean_f1\n",
    "        best_p = mean_p\n",
    "        best_r = mean_r\n",
    "        best_param = num_c\n",
    "\n",
    "print(\"Best precision: {}\".format(best_p))\n",
    "print(\"Best Recall: {}\".format(best_r))\n",
    "print(\"Best F1: {}\".format(best_f1))\n",
    "print(\"Best # candidates: {}\".format(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "# Create equivalence training data\n",
    "#####\n",
    "\n",
    "import json\n",
    "from itertools import combinations\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            \n",
    "            pairs = list(combinations(related_p_map[cid], 2))\n",
    "            \n",
    "            if test_or_dev:\n",
    "                for p1, p2 in pairs:\n",
    "                    p1_text = p_map[p1]\n",
    "                    p2_text = p_map[p2]\n",
    "                    same_cluster = False\n",
    "                    for cluster in c[\"perspectives\"]:\n",
    "                        if (p1 in cluster[\"pids\"]) and (p2 in cluster[\"pids\"]):\n",
    "                            same_cluster = True\n",
    "                            break\n",
    "                    \n",
    "                    if same_cluster:\n",
    "                        write.writerow([str(1), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                    else:\n",
    "                        write.writerow([str(0), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "            else:\n",
    "                counter = 0\n",
    "                for p1, p2 in pairs:\n",
    "                    p1_text = p_map[p1]\n",
    "                    p2_text = p_map[p2]\n",
    "                    same_cluster = False\n",
    "                    for cluster in c[\"perspectives\"]:\n",
    "                        if (p1 in cluster[\"pids\"]) and (p2 in cluster[\"pids\"]):\n",
    "                            same_cluster = True\n",
    "                            break\n",
    "                    \n",
    "                    if same_cluster:\n",
    "                        write.writerow([str(1), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                        counter += 1\n",
    "                    elif counter > 0:\n",
    "                        write.writerow([str(0), str(cid) + '-' + str(p1), str(p2), claim_text + '. ' + p1_text, p2_text])\n",
    "                        counter -= 1\n",
    "\n",
    "            \n",
    "#             if test_or_dev:\n",
    "#                 pid_set = [_pid for _text, _pid, _score in lucene_results]\n",
    "#             else:\n",
    "#                 pid_set = related_p_map[cid]\n",
    "                \n",
    "#             for pid in pid_set:\n",
    "#                 if pid in related_p_map[cid]:\n",
    "#                     p_text = p_map[pid]\n",
    "#                     write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "#                     count += 1\n",
    "            \n",
    "#             for _text, pid, _score in lucene_results:\n",
    "#                 if pid not in related_p_map[cid]:\n",
    "#                     p_text = p_map[pid]\n",
    "#                     write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "#                     count -= 1\n",
    "#                     if count <= 0:\n",
    "#                         break\n",
    "                    \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_equivalence/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_equivalence/test.tsv', test_or_dev=True)\n",
    "save_in_file(dev_claims, 'perspective_equivalence/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33570 entries, 0 to 33569\n",
      "Data columns (total 7 columns):\n",
      "undermine_score    33570 non-null float64\n",
      "support_score      33570 non-null float64\n",
      "gold               33570 non-null int64\n",
      "cid                33570 non-null int64\n",
      "pid1               33570 non-null int64\n",
      "pid2               33570 non-null int64\n",
      "pred               33570 non-null int64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate equivalence\n",
    "####\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "claim_map = {}\n",
    "for c in all_annotations:\n",
    "    claim_map[c[\"cId\"]] = c\n",
    "    \n",
    "raw_score = '../data/dataset/perspective_equivalence/test_raw_score.csv'\n",
    "test_data = '../data/dataset/perspective_equivalence/test.tsv'\n",
    "\n",
    "test_ids = []\n",
    "reader = csv.reader(open(test_data), delimiter=\"\\t\", quotechar='\"')\n",
    "for line in reader:\n",
    "    pid_cid = [int(x) for x in line[1].split('-')]\n",
    "    pid_cid.append(int(line[2]))\n",
    "    test_ids.append(pid_cid)\n",
    "        \n",
    "test_ids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "rdf = pd.read_csv(raw_score)\n",
    "rdf[\"cid\"] = rdf['pid1'] = rdf['pid2'] = rdf['pred'] = 0 \n",
    "rdf.info()\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    rdf.at[idx, 'cid'] = test_ids[idx][0]\n",
    "    rdf.at[idx, 'pid1'] = test_ids[idx][1]\n",
    "    rdf.at[idx, 'pid2'] = test_ids[idx][2]\n",
    "    rdf.at[idx, 'pred'] = 1 if row.undermine_score < row.support_score else 0\n",
    "    \n",
    "rdf.to_csv('../data/dataset/perspective_equivalence/test_raw_score_w_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8530161326620019\n",
      "Recall: 0.5080210287333485\n",
      "F1: 0.6367939767299481\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Evaluate equivalence cont.\n",
    "####\n",
    "\n",
    "unique_cids = rdf.cid.unique()\n",
    "\n",
    "tot_p = tot_r = 0\n",
    "for cid in unique_cids:\n",
    "    cdf = rdf[rdf.cid == cid]\n",
    "    tp = tot_pred = tot_gold = 0\n",
    "    for idx, row in cdf.iterrows():\n",
    "        if row.gold == 1:\n",
    "            tot_gold += 1\n",
    "\n",
    "        if row.pred == 1:\n",
    "            tot_pred += 1\n",
    "            if row.gold == 1:\n",
    "                tp += 1\n",
    "\n",
    "    if tot_gold == 0:\n",
    "        tot_p += 1\n",
    "    else:\n",
    "        tot_p += tp / tot_gold\n",
    "\n",
    "    if tot_pred == 0:\n",
    "        tot_r += 1\n",
    "    else:\n",
    "        tot_r += tp / tot_pred\n",
    "\n",
    "mean_p = tot_p / len(unique_cids)\n",
    "mean_r = tot_r / len(unique_cids)\n",
    "mean_f1 = 2 * mean_p * mean_r / (mean_p + mean_r)\n",
    "    \n",
    "\n",
    "print(\"Precision: {}\".format(mean_p))\n",
    "print(\"Recall: {}\".format(mean_r))\n",
    "print(\"F1: {}\".format(mean_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
