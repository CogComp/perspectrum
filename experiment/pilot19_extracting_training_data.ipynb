{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "139\n",
      "227\n",
      "907\n",
      "0.596471885336\n",
      "0.153252480706\n",
      "0.250275633958\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "train_topics = [u'freedom_of_speech', \n",
    "                u'human_rights', u'law',  \n",
    "                u'world_international', \n",
    "                u'economy', u'culture', \n",
    "               ]\n",
    "\n",
    "dev_topics = [  \n",
    "    u'health_and_medicine', u'society',  u'science_and_technology',u'gender', u'education', \n",
    "]\n",
    "\n",
    "test_topics = [\n",
    "    u'politics',\n",
    "    u'digital_freedom', \n",
    "    u'sports_and_entertainments', \n",
    "    u'religion', \n",
    "    u'environment', \n",
    "    u'philosophy', \n",
    "    u'ethics'\n",
    "]\n",
    "\n",
    "split_id = {}\n",
    "\n",
    "total_train_size = 0; \n",
    "total_dev_size = 0; \n",
    "total_test_size = 0; \n",
    "for c in claims:\n",
    "    cId = c['cId']\n",
    "    topics = c['topics']\n",
    "    claim_text = c['text']\n",
    "#     for topic_text in topics:\n",
    "    train_int = len(intersection(topics, train_topics))\n",
    "    dev_int = len(intersection(topics, dev_topics))\n",
    "#     assert train_int == 0 or dev_int == 0 \n",
    "    if train_int > 0: \n",
    "        total_train_size += 1\n",
    "        split_id[cId] = \"train\"\n",
    "    elif dev_int > 0: \n",
    "        total_dev_size += 1\n",
    "        split_id[cId] = \"dev\"\n",
    "    else: \n",
    "        total_test_size += 1\n",
    "        split_id[cId] = \"test\"\n",
    "#         if topic_text in train_topics:\n",
    "#             total_train_size += 1\n",
    "#             break  \n",
    "\n",
    "print(total_train_size)\n",
    "print(total_dev_size)\n",
    "print(total_test_size)\n",
    "print(len(claims))\n",
    "print(total_train_size * 1.0 / len(claims))\n",
    "print(total_dev_size * 1.0 / len(claims))\n",
    "print(total_test_size * 1.0 / len(claims))\n",
    "print((total_train_size + total_test_size + total_dev_size)* 1.0 / len(claims))\n",
    "\n",
    "\n",
    "import json\n",
    "with open('/Users/daniel/ideaProjects/perspective/data/lucene_cach/dataset_split_v0.2.json', 'w') as outfile:\n",
    "    json.dump(split_id, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating clusters of claims that do not share any perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD: create stance training data\n",
    "\n",
    "# import json \n",
    "\n",
    "# with open('../data/dataset/perspectrum_with_answers_v0.1.json') as data:\n",
    "#     all_annotations = json.load(data)\n",
    "\n",
    "# with open('../data/dataset/perspective_pool_v0.1.json') as data:\n",
    "#     perspectives = json.load(data)\n",
    "\n",
    "# p_map = {}\n",
    "# for p in perspectives: \n",
    "#     p_map[p['pId']] = p['text']\n",
    "\n",
    "\n",
    "# # create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "# import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# def save_in_file(claims, file_name): \n",
    "#     with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "#         write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for c in claims: \n",
    "#             claim_text = c[\"text\"]\n",
    "#             for p in c[\"perspectives\"]:                \n",
    "#                 for pid in p[\"pids\"]: \n",
    "#                     if \"SUPPORT\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "#                         write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "#                     if \"UNDERMINE\" in p['stance_label_3']: \n",
    "#                         p_text = p_map[pid]\n",
    "#                         write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "# split_idx = int(0.7 * len(all_annotations))  \n",
    "        \n",
    "# save_in_file(all_annotations[0:split_idx], 'perspective_stances/train.tsv')\n",
    "# save_in_file(all_annotations[1 + split_idx:], 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stance training data\n",
    "\n",
    "import json \n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    p_map[p['pId']] = p['text']\n",
    "    \n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            claim_text = c[\"text\"]\n",
    "            for p in c[\"perspectives\"]:                \n",
    "                for pid in p[\"pids\"]: \n",
    "                    if \"SUPPORT\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "#                         print(pid)\n",
    "#                         print(p_text)\n",
    "                        write.writerow([str(1), str(0), str(0), claim_text, p_text])  \n",
    "                    if \"UNDERMINE\" in p['stance_label_3']: \n",
    "                        p_text = p_map[pid]\n",
    "                        write.writerow([str(0), str(0), str(0), claim_text, p_text])  \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_stances/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_stances/test.tsv')\n",
    "save_in_file(dev_claims, 'perspective_stances/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relevance training data\n",
    "\n",
    "import json \n",
    "import random\n",
    "import query_elasticsearch as es\n",
    "\n",
    "with open('../data/dataset/perspectrum_with_answers_v0.2.json', encoding='utf-8') as data:\n",
    "    all_annotations = json.load(data)\n",
    "\n",
    "with open('../data/dataset/perspective_pool_v0.2.json', encoding='utf-8') as data:\n",
    "    perspectives = json.load(data)\n",
    "\n",
    "with open('../data/dataset/dataset_split_v0.2.json', encoding='utf-8') as data:\n",
    "    split = json.load(data)\n",
    "    \n",
    "\n",
    "all_pid_list = []\n",
    "    \n",
    "c_map ={}\n",
    "for c in all_annotations:\n",
    "    c_map[c[\"cId\"]] = c[\"text\"]\n",
    "    \n",
    "p_map = {}\n",
    "for p in perspectives: \n",
    "    pid = p['pId']\n",
    "    all_pid_list.append(pid)\n",
    "    p_map[pid] = p['text']\n",
    "\n",
    "related_p_map = {}\n",
    "for c in all_annotations:\n",
    "    cands = []\n",
    "    cid = c[\"cId\"]\n",
    "    for cluster in c[\"perspectives\"]:\n",
    "        cands += cluster[\"pids\"]\n",
    "    \n",
    "    related_p_map[cid] = set(cands)\n",
    "    \n",
    "\n",
    "\n",
    "# create pairs of claims and perspectices and save them in a csv file \n",
    "\n",
    "import csv\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def save_in_file(claims, file_name, test_or_dev=False): \n",
    "    with open('../data/dataset/' + file_name, mode='w') as employee_file:\n",
    "        write = csv.writer(employee_file, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for c in claims: \n",
    "            count = 0\n",
    "            cid = c[\"cId\"]\n",
    "            claim_text = c[\"text\"]\n",
    "            lucene_results = es.get_perspective_from_pool(claim_text, 50)\n",
    "            \n",
    "            if test_or_dev:\n",
    "                pid_set = [_pid for _text, _pid, _score in lucene_results]\n",
    "            else:\n",
    "                pid_set = related_p_map[cid]\n",
    "                \n",
    "            for pid in pid_set:\n",
    "                if pid in related_p_map[cid]:\n",
    "                    p_text = p_map[pid]\n",
    "                    write.writerow([str(1), str(cid), str(pid), claim_text, p_text])\n",
    "                    count += 1\n",
    "            \n",
    "            for _text, pid, _score in lucene_results:\n",
    "                if pid not in related_p_map[cid]:\n",
    "                    p_text = p_map[pid]\n",
    "                    write.writerow([str(0), str(cid), str(pid), claim_text , p_text])\n",
    "                    count -= 1\n",
    "                    if count <= 0:\n",
    "                        break\n",
    "                    \n",
    "\n",
    "train_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'train']\n",
    "test_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'test']\n",
    "dev_claims = [_c for _c in all_annotations if split[str(_c['cId'])] == 'dev']\n",
    "\n",
    "save_in_file(train_claims, 'perspective_relevance/train.tsv')\n",
    "save_in_file(test_claims, 'perspective_relevance/test.tsv', test_or_dev=True)\n",
    "save_in_file(dev_claims, 'perspective_relevance/dev.tsv', test_or_dev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7695837\n"
     ]
    }
   ],
   "source": [
    "# WIP - WIP - WIP - Evaluate BERT results on perpsective relevance\n",
    "import csv\n",
    "\n",
    "raw_score = '../data/dataset/perspective_relevance/test_raw_score.csv'\n",
    "test_data = '../data/dataset/perspective_relevance/test.tsv'\n",
    "\n",
    "test_cids = []\n",
    "for line in open(test_data):\n",
    "    line = line.rstrip()\n",
    "    if line:\n",
    "        test_cids.append(line.split('\\t')[1])\n",
    "        \n",
    "test_cids.pop(0) # somehow the bert script ignores the first instance during reading\n",
    "\n",
    "\n",
    "reader = csv.DictReader(open(raw_score, 'r'))\n",
    "count = 0\n",
    "for line in reader:\n",
    "    cid = test_cids[count]\n",
    "    und_score = float(line['undermine_score']) \n",
    "    sup_score = float(line['support_score']) \n",
    "    label = 1 if sup_score > und_score else 0\n",
    "    \n",
    "    count += 1\n",
    "    break;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
